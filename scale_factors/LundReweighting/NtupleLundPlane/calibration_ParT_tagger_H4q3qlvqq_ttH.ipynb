{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/00\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "from matplotlib import pyplot as plt\n",
    "import mplhep as hep\n",
    "hep.style.use(\"CMS\")\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "import numpy as np\n",
    "import correctionlib\n",
    "import awkward as ak\n",
    "import fastjet\n",
    "from coffea.nanoevents.methods import vector\n",
    "from coffea import nanoevents\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "from hist import Hist\n",
    "ak.behavior.update(vector.behavior)\n",
    "import sys\n",
    "sys.path.append('/home/pku/zhaoyz/Higgs/LundReweighting/utils')\n",
    "from LundReweighter import *\n",
    "# import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load signal NanoAOD files and do pre-selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #first way to load root file is using nanoevents, but suffer from low process speed\n",
    "events = nanoevents.NanoEventsFactory.from_root(\n",
    "        # \"/data/bond/zhaoyz/CustNano/HWWPFNano/2018/Signal_MERGED/GluGluHToWW_Pt-200ToInf_M-125_TuneCP5_MINLO_13TeV-powheg-pythia8_RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MERGED.root\",\n",
    "        # \"/data/bond/zhaoyz/CustNano/HWWPFNano/2018/Signal_MERGED/VBFHToWWToAny_M-125_TuneCP5_withDipoleRecoil_13TeV-powheg-jhugen751-pythia8_RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MERGED.root\",\n",
    "        \"/data/bond/zhaoyz/CustNano/HWWPFNano/2018/Signal_MERGED/ttHToNonbb_M125_TuneCP5_13TeV-powheg-pythia8_RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MERGED.root\",\n",
    "        # \"/data/bond/zhaoyz/CustNano/HWWPFNano/2018/Signal_MERGED/HWminusJ_HToWW_M-125_TuneCP5_13TeV-powheg-jhugen727-pythia8_RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MERGED.root\",\n",
    "        # \"/data/bond/zhaoyz/CustNano/HWWPFNano/2018/Signal_MERGED/HZJ_HToWW_M-125_TuneCP5_13TeV-powheg-jhugen727-pythia8_RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MERGED.root\"\n",
    "        schemaclass=nanoevents.NanoAODSchema,\n",
    "    ).events()\n",
    "\n",
    "#second way to load root file is using uproot.lazy\n",
    "# events = uproot.lazy({\"/data/bond/zhaoyz/CustNano/HWWPFNano/2018/Signal_MERGED/ttHToNonbb_M125_TuneCP5_13TeV-powheg-pythia8_RunIISummer20UL18MiniAODv2-106X_upgrade2018_realistic_v16_L1v1-v2/MERGED.root\":\"Events\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 1\n",
    "n_use = int(frac*len(events))\n",
    "events_1 = events[:n_use]\n",
    "del events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepMETResponseTune',\n",
       " 'SoftActivityJetHT2',\n",
       " 'Jet',\n",
       " 'SoftActivityJetHT5',\n",
       " 'GenIsolatedPhoton',\n",
       " 'PSWeight',\n",
       " 'ChsMET',\n",
       " 'DeepMETResolutionTune',\n",
       " 'fixedGridRhoFastjetCentralCalo',\n",
       " 'event',\n",
       " 'AK15Puppi',\n",
       " 'HLTriggerFinalPath',\n",
       " 'CorrT1METJet',\n",
       " 'PuppiMET',\n",
       " 'LHEPart',\n",
       " 'LHEReweightingWeight',\n",
       " 'fixedGridRhoFastjetCentralChargedPileUp',\n",
       " 'GenDressedLepton',\n",
       " 'Photon',\n",
       " 'OtherPV',\n",
       " 'PFCands',\n",
       " 'btagWeight',\n",
       " 'GenFatJetCands',\n",
       " 'RawPuppiMET',\n",
       " 'SubJet',\n",
       " 'LHEPdfWeight',\n",
       " 'GenJetSVs',\n",
       " 'GenSubJetAK15',\n",
       " 'JetPFCands',\n",
       " 'FsrPhoton',\n",
       " 'L1PreFiringWeight',\n",
       " 'LHEScaleWeight',\n",
       " 'GenPart',\n",
       " 'SubGenJetAK8',\n",
       " 'SV',\n",
       " 'LHEWeight',\n",
       " 'SoftActivityJetNjets10',\n",
       " 'HLT',\n",
       " 'GenJetAK8',\n",
       " 'SoftActivityJetNjets5',\n",
       " 'L1simulation',\n",
       " 'IsoTrack',\n",
       " 'LHE',\n",
       " 'fixedGridRhoFastjetCentral',\n",
       " 'SoftActivityJetNjets2',\n",
       " 'SoftActivityJet',\n",
       " 'Muon',\n",
       " 'GenJet',\n",
       " 'AK15PuppiSubJet',\n",
       " 'GenMET',\n",
       " 'PV',\n",
       " 'HLTriggerFirstPath',\n",
       " 'Electron',\n",
       " 'RawMET',\n",
       " 'L1Reco',\n",
       " 'Generator',\n",
       " 'TkMET',\n",
       " 'CaloMET',\n",
       " 'JetSVs',\n",
       " 'Flag',\n",
       " 'GenJetCands',\n",
       " 'genTtbarId',\n",
       " 'FatJet',\n",
       " 'GenVtx',\n",
       " 'LowPtElectron',\n",
       " 'SoftActivityJetHT10',\n",
       " 'L1',\n",
       " 'run',\n",
       " 'HTXS',\n",
       " 'GenFatJetSVs',\n",
       " 'MET',\n",
       " 'fixedGridRhoFastjetAll',\n",
       " 'Tau',\n",
       " 'GenJetAK15',\n",
       " 'genWeight',\n",
       " 'SoftActivityJetHT',\n",
       " 'boostedTau',\n",
       " 'TrigObj',\n",
       " 'FatJetPFCands',\n",
       " 'luminosityBlock',\n",
       " 'fixedGridRhoFastjetCentralNeutral',\n",
       " 'FatJetSVs',\n",
       " 'Pileup',\n",
       " 'GenCands',\n",
       " 'GenVisTau']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick look at the fields of signal files\n",
    "events_1.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_fields = [\"Electron\",\"Muon\",\"FatJet\",\"genWeight\",\"GenPart\",\"FatJetPFCands\",\"PFCands\"]\n",
    "filtered_events = events_1[desired_fields]\n",
    "del events_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define necessary functions to run the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad array with given value\n",
    "def pad_val(\n",
    "    arr: ak.Array,\n",
    "    target: int,\n",
    "    value: float, #value can also be Bool variable \n",
    "    axis: int = 0,\n",
    "    to_numpy: bool = True,\n",
    "    clip: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    pads awkward array up to ``target`` index along axis ``axis`` with value ``value``,\n",
    "    optionally converts to numpy array\n",
    "    \"\"\"\n",
    "    padded_arr = ak.fill_none(ak.pad_none(arr, target, axis=axis, clip=clip), value, axis=axis)\n",
    "    # pad_none will fill the array to target length with \"None\" for dedicated axis\n",
    "    # \"clip\" means cut the array to the target length or not\n",
    "    # fill_none will replace \"None\" value to some value\n",
    "    return padded_arr.to_numpy() if to_numpy else padded_arr\n",
    "\n",
    "def add_selection(\n",
    "    name: str,\n",
    "    sel: np.ndarray,\n",
    "    selection: PackedSelection,\n",
    "    cutflow: dict = None,\n",
    "    isData: bool = False,\n",
    "    signGenWeights: ak.Array = None,\n",
    "):\n",
    "    \"\"\"adds selection to PackedSelection object and the cutflow dictionary\"\"\"\n",
    "    selection.add(name, sel)\n",
    "    if cutflow is not None: #only add to cutflow dictionary if cutflow is not None\n",
    "        cutflow[name] = (\n",
    "            np.sum(selection.all(*selection.names))\n",
    "            if isData\n",
    "            # add up sign of genWeights for MC\n",
    "            else np.sum(signGenWeights[selection.all(*selection.names)])\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-selection:\n",
    "#1.Leading jet pT > 400GeV, maximum jet mass > 50GeV\n",
    "#2.Require 2 or 3 AK8 jet with pT > 200GeV\n",
    "#3.Veto (mini-)Isolated leptons\n",
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(filtered_events[\"genWeight\"]) #get genWeight sign, because only the sign matters\n",
    "n_events = len(filtered_events) if isData else int(np.sum(signGenWeights)) #events number for MC events should be the sum of \"sign\"\n",
    "selection = PackedSelection() #initialize a new object\n",
    "\n",
    "cutflow = {}\n",
    "# cutflow[\"all\"] = len(events) #shouldn't be n_events?\n",
    "cutflow[\"all\"] = n_events\n",
    "preselection_cut_vals = {\"pt\": 200, \"msd\": 20, \"leading_pt\":400,\"maximum_mass\":50}\n",
    "num_jets = 2\n",
    "\n",
    "# fatjets = corrections.get_jec_jets(events, \"2018\")\n",
    "fatjets = filtered_events.FatJet\n",
    "\n",
    "preselection_cut_1 = pad_val(\n",
    "        ( ak.max(filtered_events.FatJet.pt, axis = 1) > preselection_cut_vals[\"leading_pt\"])\n",
    "        * (ak.max(filtered_events.FatJet.msoftdrop, axis = 1) > preselection_cut_vals[\"maximum_mass\"]), #mass and pT cut of each jet in event\n",
    "        len(filtered_events), #pad to num_jets length\n",
    "        False,  #pad with value False\n",
    "        )\n",
    "# finally with the length of events number, \"1\" for all jets are pT > pT_cut and mass > mass_cut\n",
    " # N.B. here clip always = True\n",
    "\n",
    "add_selection(\n",
    "    \"leading pT and maximum mass\", #string name\n",
    "    preselection_cut_1.astype(bool), #selection content\n",
    "    selection, #PackedSelection object\n",
    "    cutflow, #cut-flow dict, storing events number after each cut\n",
    "    isData,\n",
    "    signGenWeights,#sum the signGenWeights for events which pass the selection\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "preselection_cut_2 = np.prod(\n",
    "    pad_val(\n",
    "        (filtered_events.FatJet.pt > preselection_cut_vals[\"pt\"]),\n",
    "        # * (events.FatJet.msoftdrop > preselection_cut_vals[\"msd\"]), #mass and pT cut of each jet in event\n",
    "        num_jets, #pad to num_jets length\n",
    "        False,  #pad with value False\n",
    "        axis=1, #pad to axis=1\n",
    "    ),\n",
    "    axis=1,\n",
    ")# finally with the length of events number, \"1\" for all jets are pT > pT_cut and mass > mass_cut\n",
    " # N.B. here clip always = True\n",
    "\n",
    "add_selection(\n",
    "    \"at least 2 AK8 jet with pT >200GeV\", #string name\n",
    "    preselection_cut_2.astype(bool), #selection content\n",
    "    selection, #PackedSelection object\n",
    "    cutflow, #cut-flow dict, storing events number after each cut\n",
    "    isData,\n",
    "    signGenWeights,#sum the signGenWeights for events which pass the selection\n",
    ")\n",
    "\n",
    "preselection_cut_3 = pad_val(\n",
    "        (ak.num(filtered_events.FatJet.pt) == 2) | (ak.num(filtered_events.FatJet.pt) == 3) , #mass and pT cut of each jet in event\n",
    "        len(filtered_events), #pad to num_jets length\n",
    "        False,  #pad with value False\n",
    "        )\n",
    "\n",
    "add_selection(\n",
    "    \"2 or 3 AK8 jet\", #string name\n",
    "    preselection_cut_3.astype(bool), #selection content\n",
    "    selection, #PackedSelection object\n",
    "    cutflow, #cut-flow dict, storing events number after each cut\n",
    "    isData,\n",
    "    signGenWeights,#sum the signGenWeights for events which pass the selection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 7176599,\n",
       " 'leading pT and maximum mass': 557390.0,\n",
       " 'at least 2 AK8 jet with pT >200GeV': 509278.0,\n",
       " '2 or 3 AK8 jet': 470339.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events_1 = filtered_events[selection.all(*selection.names)]\n",
    "del filtered_events\n",
    "filtered_events = filtered_events_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [{Electron: [Electron, ... ] type='516751 * {\"Electron\": var * electron, ...'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = PackedSelection() #initialize a new object\n",
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(filtered_events[\"genWeight\"]) #get genWeight sign, because only the sign matters\n",
    "n_events = len(filtered_events) if isData else int(np.sum(signGenWeights)) #events number for MC events should be the sum of \"sign\"\n",
    "selection = PackedSelection() #initialize a new object\n",
    "\n",
    "cutflow = {}\n",
    "# cutflow[\"all\"] = len(events) #shouldn't be n_events?\n",
    "cutflow[\"all\"] = n_events\n",
    "\n",
    "#veto (mini-)isolated muons\n",
    "#referring to : https://github.com/farakiko/boostedhiggs/blob/ec53b97857bf64aa4d75f639e290181e65a55b4c/boostedhiggs/hwwprocessor.py#L185-L237\n",
    "muons = ak.with_field(filtered_events.Muon, 0, \"flavor\")\n",
    "electrons = ak.with_field(filtered_events.Electron, 1, \"flavor\")\n",
    "\n",
    "# muons\n",
    "loose_muons = (\n",
    "    (((muons.pt > 30) & (muons.pfRelIso04_all < 0.25)) | (muons.pt > 55))\n",
    "    & (np.abs(muons.eta) < 2.4)\n",
    "    & (muons.looseId)\n",
    ")\n",
    "n_loose_muons = ak.sum(loose_muons, axis=1)\n",
    "good_muons = (\n",
    "    (muons.pt > 30)\n",
    "    & (np.abs(muons.eta) < 2.4)\n",
    "    & (np.abs(muons.dz) < 0.1)\n",
    "    & (np.abs(muons.dxy) < 0.05)\n",
    "    & (muons.sip3d <= 4.0)\n",
    "    & muons.mediumId\n",
    ")\n",
    "n_good_muons = ak.sum(good_muons, axis=1)\n",
    "\n",
    "# electrons\n",
    "loose_electrons = (\n",
    "    (((electrons.pt > 38) & (electrons.pfRelIso03_all < 0.25)) | (electrons.pt > 120))\n",
    "    & (np.abs(electrons.eta) < 2.4)\n",
    "    & ((np.abs(electrons.eta) < 1.44) | (np.abs(electrons.eta) > 1.57))\n",
    "    & (electrons.cutBased >= 2)\n",
    "    # & (electrons.cutBased >= electrons.LOOSE) #cut-based ID Fall17 V2 (0:fail, 1:veto, 2:loose, 3:medium, 4:tight)\n",
    ")\n",
    "n_loose_electrons = ak.sum(loose_electrons, axis=1)\n",
    "good_electrons = (\n",
    "    (electrons.pt > 38)\n",
    "    & (np.abs(electrons.eta) < 2.4)\n",
    "    & ((np.abs(electrons.eta) < 1.44) | (np.abs(electrons.eta) > 1.57))\n",
    "    & (np.abs(electrons.dz) < 0.1)\n",
    "    & (np.abs(electrons.dxy) < 0.05)\n",
    "    & (electrons.sip3d <= 4.0)\n",
    "    & (electrons.mvaFall17V2noIso_WP90)\n",
    ")\n",
    "n_good_electrons = ak.sum(good_electrons, axis=1)\n",
    "\n",
    "n_leptons = n_loose_electrons + n_good_electrons + n_loose_muons + n_good_muons\n",
    "\n",
    "preselection_cut_4 = pad_val(\n",
    "        (n_leptons == 0) , #mass and pT cut of each jet in event\n",
    "        len(filtered_events), #pad to num_jets length\n",
    "        False,  #pad with value False\n",
    "        )\n",
    "\n",
    "add_selection(\n",
    "    \"no (mini-)isolated leptons\", #string name\n",
    "    preselection_cut_4.astype(bool), #selection content\n",
    "    selection, #PackedSelection object\n",
    "    cutflow, #cut-flow dict, storing events number after each cut\n",
    "    isData,\n",
    "    signGenWeights,#sum the signGenWeights for events which pass the selection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 470339, 'no (mini-)isolated leptons': 277187.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events_1 = filtered_events[selection.all(*selection.names)]\n",
    "del filtered_events\n",
    "filtered_events = filtered_events_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = PackedSelection() #initialize a new object\n",
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(filtered_events[\"genWeight\"]) #get genWeight sign, because only the sign matters\n",
    "n_events = len(filtered_events) if isData else int(np.sum(signGenWeights)) #events number for MC events should be the sum of \"sign\"\n",
    "selection = PackedSelection() #initialize a new object\n",
    "\n",
    "cutflow = {}\n",
    "# cutflow[\"all\"] = len(events) #shouldn't be n_events?\n",
    "cutflow[\"all\"] = n_events\n",
    "\n",
    "#require WW decaying to 4q, because we want to calibrate H3q4q jet at first stage\n",
    "d_PDGID = 1\n",
    "u_PDGID = 2\n",
    "s_PDGID = 3\n",
    "c_PDGID = 4\n",
    "b_PDGID = 5\n",
    "g_PDGID = 21\n",
    "TOP_PDGID = 6\n",
    "\n",
    "ELE_PDGID = 11\n",
    "vELE_PDGID = 12\n",
    "MU_PDGID = 13\n",
    "vMU_PDGID = 14\n",
    "TAU_PDGID = 15\n",
    "vTAU_PDGID = 16\n",
    "\n",
    "Z_PDGID = 23\n",
    "W_PDGID = 24\n",
    "HIGGS_PDGID = 25\n",
    "Y_PDGID = 35\n",
    "\n",
    "b_PDGIDS = [511, 521, 523]\n",
    "\n",
    "GRAV_PDGID = 39\n",
    "\n",
    "GEN_FLAGS = [\"fromHardProcess\", \"isLastCopy\"]\n",
    "\n",
    "FILL_NONE_VALUE = -99999\n",
    "PAD_VAL = -99999\n",
    "\n",
    "skim_vars = {\n",
    "    \"eta\": \"Eta\",\n",
    "    \"phi\": \"Phi\",\n",
    "    \"mass\": \"Mass\",\n",
    "    \"pt\": \"Pt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only HWW decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly selection only HWW decay:\n",
    "selection = PackedSelection() #initialize a new object\n",
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(filtered_events[\"genWeight\"]) #get genWeight sign, because only the sign matters\n",
    "n_events = len(filtered_events) if isData else int(np.sum(signGenWeights)) #events number for MC events should be the sum of \"sign\"\n",
    "selection = PackedSelection() #initialize a new object\n",
    "\n",
    "cutflow = {}\n",
    "# cutflow[\"all\"] = len(events) #shouldn't be n_events?\n",
    "cutflow[\"all\"] = n_events\n",
    "\n",
    "\n",
    "# finding the gen higgs\n",
    "higgs = filtered_events.GenPart[\n",
    "    (abs(filtered_events.GenPart.pdgId) == HIGGS_PDGID) * filtered_events.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "# saving 4-vector info\n",
    "GenHiggsVars = {f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()}\n",
    "\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# saving whether H->bb or H->VV\n",
    "GenHiggsVars[\"GenHiggsChildren\"] = abs(higgs_children.pdgId[:, :, 0]).to_numpy()\n",
    "\n",
    "# finding WW children\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "\n",
    "# Hbb = higgs[ak.sum(is_bb, axis=2) == 2]\n",
    "HWW = higgs[ak.sum(is_WW, axis=2) == 2]\n",
    "\n",
    "# checking that there are 2 b's and 2 V's\n",
    "has_WW = ak.sum(ak.flatten(is_WW, axis=2), axis=1) == 2\n",
    "\n",
    "add_selection(\n",
    "    \"HtoWW\",\n",
    "    has_WW, \n",
    "    selection, \n",
    "    cutflow, \n",
    "    False, \n",
    "    signGenWeights)\n",
    "# print(selection_all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [{Electron: [Electron, ... ] type='302693 * {\"Electron\": var * electron, ...'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events_1 = filtered_events[selection.all(*selection.names)]\n",
    "del filtered_events\n",
    "filtered_events = filtered_events_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [{Electron: [Electron, ... ] type='143017 * {\"Electron\": var * electron, ...'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may take much time\n",
    "#Then do other test:\n",
    "selection = PackedSelection() #initialize a new object\n",
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(filtered_events[\"genWeight\"]) #get genWeight sign, because only the sign matters\n",
    "n_events = len(filtered_events) if isData else int(np.sum(signGenWeights)) #events number for MC events should be the sum of \"sign\"\n",
    "selection = PackedSelection() #initialize a new object\n",
    "\n",
    "cutflow = {}\n",
    "# cutflow[\"all\"] = len(events) #shouldn't be n_events?\n",
    "cutflow[\"all\"] = n_events\n",
    "# finding the gen higgs\n",
    "higgs = filtered_events.GenPart[\n",
    "    (abs(filtered_events.GenPart.pdgId) == HIGGS_PDGID) * filtered_events.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "# saving 4-vector info\n",
    "GenHiggsVars = {f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()}\n",
    "\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# saving whether H->bb or H->VV\n",
    "GenHiggsVars[\"GenHiggsChildren\"] = abs(higgs_children.pdgId[:, :, 0]).to_numpy()\n",
    "\n",
    "# finding WW children\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "\n",
    "# Hbb = higgs[ak.sum(is_bb, axis=2) == 2]\n",
    "HWW = higgs[ak.sum(is_WW, axis=2) == 2]\n",
    "\n",
    "# checking that there are 2 b's and 2 V's\n",
    "has_WW = ak.sum(ak.flatten(is_WW, axis=2), axis=1) == 2\n",
    "\n",
    "add_selection(\n",
    "    \"HtoWW\",\n",
    "    has_WW, \n",
    "    selection, \n",
    "    cutflow, \n",
    "    False, \n",
    "    signGenWeights)\n",
    "# print(selection_all_q)\n",
    "\n",
    "\n",
    "\n",
    "# saving WW 4-vector info\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "#for normal ggF, VBF HWW signal\n",
    "GenWWVars = {\n",
    "    f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#for ttHnonbb HWW signal, because there may not be H-->WW events\n",
    "# GenWWVars = {\n",
    "#     f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1) for (var, key) in skim_vars.items()\n",
    "#     }\n",
    "\n",
    "# checking that each W has 2 q children, so finally the HWW jet will be H4q or H3q jet\n",
    "WW_children = WW.children\n",
    "\n",
    "quarks = abs(WW_children.pdgId) <= b_PDGID #get all the 2 Ws daughter PDGID <=5 information\n",
    "\n",
    "selection_all_q = ak.all(ak.all(quarks, axis=2), axis=1) #check if all the children of 2 Ws are quarks or not\n",
    "#so first check 2nd axis, and then check 1st axis\n",
    "add_selection(\n",
    "    \"WW decays to 4q\",\n",
    "    selection_all_q, \n",
    "    selection, \n",
    "    cutflow, \n",
    "    False, \n",
    "    signGenWeights)\n",
    "# print(selection_all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 131157, 'HtoWW': 131157.0, 'WW decays to 4q': 73064.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick look at the cut-flow\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store the PFCands, GenEtaPhi, Higgs candidate AK8 jet 4-vector information for Lund Plane use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [{Electron: [], Muon: [, ... ] type='79444 * {\"Electron\": var * electron,...'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_after_cut = filtered_events[selection.all(*selection.names)]\n",
    "# del filtered_events\n",
    "events_after_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb 单元格 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m is_WW \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(higgs_children\u001b[39m.\u001b[39mpdgId) \u001b[39m==\u001b[39m W_PDGID\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m WW \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mflatten(higgs_children[is_WW], axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m GenWWVars \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenWW\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: pad_val(WW[var], \u001b[39m2\u001b[39m, FILL_NONE_VALUE, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (var, key) \u001b[39min\u001b[39;00m skim_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m GenW1Vars \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenWW\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: pad_val(WW[var], \u001b[39m2\u001b[39m, FILL_NONE_VALUE, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:,\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m (var, key) \u001b[39min\u001b[39;00m skim_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m GenW2Vars \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenWW\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: pad_val(WW[var], \u001b[39m2\u001b[39m, FILL_NONE_VALUE, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:,\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m (var, key) \u001b[39min\u001b[39;00m skim_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     }\n",
      "\u001b[1;32m/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb 单元格 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m is_WW \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(higgs_children\u001b[39m.\u001b[39mpdgId) \u001b[39m==\u001b[39m W_PDGID\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m WW \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mflatten(higgs_children[is_WW], axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m GenWWVars \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenWW\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: pad_val(WW[var], \u001b[39m2\u001b[39;49m, FILL_NONE_VALUE, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m (var, key) \u001b[39min\u001b[39;00m skim_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m GenW1Vars \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenWW\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: pad_val(WW[var], \u001b[39m2\u001b[39m, FILL_NONE_VALUE, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:,\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m (var, key) \u001b[39min\u001b[39;00m skim_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m GenW2Vars \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenWW\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m: pad_val(WW[var], \u001b[39m2\u001b[39m, FILL_NONE_VALUE, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:,\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m (var, key) \u001b[39min\u001b[39;00m skim_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     }\n",
      "\u001b[1;32m/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb 单元格 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpad_val\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     arr: ak\u001b[39m.\u001b[39mArray,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     target: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     clip: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    pads awkward array up to ``target`` index along axis ``axis`` with value ``value``,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    optionally converts to numpy array\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     padded_arr \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39;49mfill_none(ak\u001b[39m.\u001b[39;49mpad_none(arr, target, axis\u001b[39m=\u001b[39;49maxis, clip\u001b[39m=\u001b[39;49mclip), value, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# pad_none will fill the array to target length with \"None\" for dedicated axis\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# \"clip\" means cut the array to the target length or not\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# fill_none will replace \"None\" value to some value\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnode06/home/pku/zhaoyz/Higgs/boostedHWW/scale_factors/LundReweighting/NtupleLundPlane/calibration_ParT_tagger_H4q3qlvqq_ttH.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m padded_arr\u001b[39m.\u001b[39mto_numpy() \u001b[39mif\u001b[39;00m to_numpy \u001b[39melse\u001b[39;00m padded_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/awkward/operations/structure.py:2899\u001b[0m, in \u001b[0;36mfill_none\u001b[0;34m(array, value, axis, highlevel, behavior)\u001b[0m\n\u001b[1;32m   2895\u001b[0m             layout \u001b[39m=\u001b[39m maybe_fillna(layout)\n\u001b[1;32m   2897\u001b[0m         \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39m_util\u001b[39m.\u001b[39mtransform_child_layouts(transform, layout, depth, posaxis)\n\u001b[0;32m-> 2899\u001b[0m out \u001b[39m=\u001b[39m transform(arraylayout, \u001b[39m1\u001b[39;49m, axis)\n\u001b[1;32m   2901\u001b[0m \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39m_util\u001b[39m.\u001b[39mmaybe_wrap_like(out, array, behavior, highlevel)\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/awkward/operations/structure.py:2897\u001b[0m, in \u001b[0;36mfill_none.<locals>.transform\u001b[0;34m(layout, depth, posaxis)\u001b[0m\n\u001b[1;32m   2894\u001b[0m \u001b[39mif\u001b[39;00m posaxis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m depth:\n\u001b[1;32m   2895\u001b[0m     layout \u001b[39m=\u001b[39m maybe_fillna(layout)\n\u001b[0;32m-> 2897\u001b[0m \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39;49m_util\u001b[39m.\u001b[39;49mtransform_child_layouts(transform, layout, depth, posaxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/awkward/_util.py:1335\u001b[0m, in \u001b[0;36mtransform_child_layouts\u001b[0;34m(transform, layout, depth, user, keep_parameters)\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39mlayout\u001b[39m.\u001b[39mEmptyArray(layout\u001b[39m.\u001b[39midentities, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1333\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(layout, ak\u001b[39m.\u001b[39mlayout\u001b[39m.\u001b[39mRegularArray):\n\u001b[1;32m   1334\u001b[0m     \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39mlayout\u001b[39m.\u001b[39mRegularArray(\n\u001b[0;32m-> 1335\u001b[0m         transform(layout\u001b[39m.\u001b[39;49mcontent, depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, user),\n\u001b[1;32m   1336\u001b[0m         layout\u001b[39m.\u001b[39msize,\n\u001b[1;32m   1337\u001b[0m         \u001b[39mlen\u001b[39m(layout),\n\u001b[1;32m   1338\u001b[0m         layout\u001b[39m.\u001b[39midentities,\n\u001b[1;32m   1339\u001b[0m         layout\u001b[39m.\u001b[39mparameters \u001b[39mif\u001b[39;00m keep_parameters \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1340\u001b[0m     )\n\u001b[1;32m   1342\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(layout, ak\u001b[39m.\u001b[39mlayout\u001b[39m.\u001b[39mListArray32):\n\u001b[1;32m   1343\u001b[0m     \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39mlayout\u001b[39m.\u001b[39mListArray32(\n\u001b[1;32m   1344\u001b[0m         layout\u001b[39m.\u001b[39mstarts,\n\u001b[1;32m   1345\u001b[0m         layout\u001b[39m.\u001b[39mstops,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         layout\u001b[39m.\u001b[39mparameters \u001b[39mif\u001b[39;00m keep_parameters \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1349\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/awkward/operations/structure.py:2895\u001b[0m, in \u001b[0;36mfill_none.<locals>.transform\u001b[0;34m(layout, depth, posaxis)\u001b[0m\n\u001b[1;32m   2892\u001b[0m     \u001b[39mreturn\u001b[39;00m layout\n\u001b[1;32m   2894\u001b[0m \u001b[39mif\u001b[39;00m posaxis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m depth:\n\u001b[0;32m-> 2895\u001b[0m     layout \u001b[39m=\u001b[39m maybe_fillna(layout)\n\u001b[1;32m   2897\u001b[0m \u001b[39mreturn\u001b[39;00m ak\u001b[39m.\u001b[39m_util\u001b[39m.\u001b[39mtransform_child_layouts(transform, layout, depth, posaxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/awkward/operations/structure.py:2876\u001b[0m, in \u001b[0;36mfill_none.<locals>.maybe_fillna\u001b[0;34m(layout)\u001b[0m\n\u001b[1;32m   2874\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmaybe_fillna\u001b[39m(layout):\n\u001b[1;32m   2875\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(layout, ak\u001b[39m.\u001b[39m_util\u001b[39m.\u001b[39moptiontypes):\n\u001b[0;32m-> 2876\u001b[0m         \u001b[39mreturn\u001b[39;00m layout\u001b[39m.\u001b[39;49mfillna(valuelayout)\n\u001b[1;32m   2877\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m         \u001b[39mreturn\u001b[39;00m layout\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/awkward/operations/convert.py:4774\u001b[0m, in \u001b[0;36m_form_to_layout\u001b[0;34m(form, container, partnum, key_format, length, lazy_cache, lazy_cache_key)\u001b[0m\n\u001b[1;32m   4768\u001b[0m     \u001b[39mreturn\u001b[39;00m _form_to_layout_class[\u001b[39mtype\u001b[39m(form), form\u001b[39m.\u001b[39moffsets](\n\u001b[1;32m   4769\u001b[0m         offsets, content, identities, parameters\n\u001b[1;32m   4770\u001b[0m     )\n\u001b[1;32m   4772\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(form, ak\u001b[39m.\u001b[39mforms\u001b[39m.\u001b[39mNumpyForm):\n\u001b[1;32m   4773\u001b[0m     raw_array \u001b[39m=\u001b[39m _asbuf(\n\u001b[0;32m-> 4774\u001b[0m         container[key_format(form_key\u001b[39m=\u001b[39;49mfk, attribute\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m, partition\u001b[39m=\u001b[39;49mpartnum)]\n\u001b[1;32m   4775\u001b[0m     )\n\u001b[1;32m   4777\u001b[0m     dtype_inner_shape \u001b[39m=\u001b[39m form\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m   4778\u001b[0m     \u001b[39mif\u001b[39;00m dtype_inner_shape\u001b[39m.\u001b[39msubdtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/coffea/nanoevents/mapping/base.py:90\u001b[0m, in \u001b[0;36mBaseSourceMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_access_log\u001b[39m.\u001b[39mappend(handle_name)\n\u001b[1;32m     87\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_column_handle(\n\u001b[1;32m     88\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_source(uuid, treepath), handle_name\n\u001b[1;32m     89\u001b[0m     )\n\u001b[0;32m---> 90\u001b[0m     stack\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_column(handle, start, stop))\n\u001b[1;32m     91\u001b[0m \u001b[39melif\u001b[39;00m node\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m!\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     92\u001b[0m     tname \u001b[39m=\u001b[39m node[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:149\u001b[0m, in \u001b[0;36mUprootSourceMapping.extract_column\u001b[0;34m(self, columnhandle, start, stop)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_column\u001b[39m(\u001b[39mself\u001b[39m, columnhandle, start, stop):\n\u001b[1;32m    148\u001b[0m     \u001b[39m# make sure uproot is single-core since our calling context might not be\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m columnhandle\u001b[39m.\u001b[39;49marray(\n\u001b[1;32m    150\u001b[0m         entry_start\u001b[39m=\u001b[39;49mstart,\n\u001b[1;32m    151\u001b[0m         entry_stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    152\u001b[0m         decompression_executor\u001b[39m=\u001b[39;49muproot\u001b[39m.\u001b[39;49msource\u001b[39m.\u001b[39;49mfutures\u001b[39m.\u001b[39;49mTrivialExecutor(),\n\u001b[1;32m    153\u001b[0m         interpretation_executor\u001b[39m=\u001b[39;49muproot\u001b[39m.\u001b[39;49msource\u001b[39m.\u001b[39;49mfutures\u001b[39m.\u001b[39;49mTrivialExecutor(),\n\u001b[1;32m    154\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:2208\u001b[0m, in \u001b[0;36mTBranch.array\u001b[0;34m(self, interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library)\u001b[0m\n\u001b[1;32m   2202\u001b[0m             \u001b[39mfor\u001b[39;00m (\n\u001b[1;32m   2203\u001b[0m                 basket_num,\n\u001b[1;32m   2204\u001b[0m                 range_or_basket,\n\u001b[1;32m   2205\u001b[0m             ) \u001b[39min\u001b[39;00m branch\u001b[39m.\u001b[39mentries_to_ranges_or_baskets(entry_start, entry_stop):\n\u001b[1;32m   2206\u001b[0m                 ranges_or_baskets\u001b[39m.\u001b[39mappend((branch, basket_num, range_or_basket))\n\u001b[0;32m-> 2208\u001b[0m _ranges_or_baskets_to_arrays(\n\u001b[1;32m   2209\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2210\u001b[0m     ranges_or_baskets,\n\u001b[1;32m   2211\u001b[0m     branchid_interpretation,\n\u001b[1;32m   2212\u001b[0m     entry_start,\n\u001b[1;32m   2213\u001b[0m     entry_stop,\n\u001b[1;32m   2214\u001b[0m     decompression_executor,\n\u001b[1;32m   2215\u001b[0m     interpretation_executor,\n\u001b[1;32m   2216\u001b[0m     library,\n\u001b[1;32m   2217\u001b[0m     arrays,\n\u001b[1;32m   2218\u001b[0m     \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2219\u001b[0m )\n\u001b[1;32m   2221\u001b[0m _fix_asgrouped(\n\u001b[1;32m   2222\u001b[0m     arrays, expression_context, branchid_interpretation, library, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2223\u001b[0m )\n\u001b[1;32m   2225\u001b[0m \u001b[39mif\u001b[39;00m array_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:3484\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets)\u001b[0m\n\u001b[1;32m   3482\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, uproot\u001b[39m.\u001b[39msource\u001b[39m.\u001b[39mchunk\u001b[39m.\u001b[39mChunk):\n\u001b[1;32m   3483\u001b[0m     args \u001b[39m=\u001b[39m range_args[(obj\u001b[39m.\u001b[39mstart, obj\u001b[39m.\u001b[39mstop)]\n\u001b[0;32m-> 3484\u001b[0m     decompression_executor\u001b[39m.\u001b[39;49msubmit(chunk_to_basket, obj, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   3486\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, uproot\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mTBasket\u001b[39m.\u001b[39mModel_TBasket):\n\u001b[1;32m   3487\u001b[0m     interpretation_executor\u001b[39m.\u001b[39msubmit(basket_to_array, obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/source/futures.py:73\u001b[0m, in \u001b[0;36mTrivialExecutor.submit\u001b[0;34m(self, task, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msubmit\u001b[39m(\u001b[39mself\u001b[39m, task, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     70\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    Immediately runs ``task(*args)``.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m TrivialFuture(task(\u001b[39m*\u001b[39;49margs))\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/behaviors/TBranch.py:3414\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays.<locals>.chunk_to_basket\u001b[0;34m(chunk, branch, basket_num)\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   3413\u001b[0m     cursor \u001b[39m=\u001b[39m uproot\u001b[39m.\u001b[39msource\u001b[39m.\u001b[39mcursor\u001b[39m.\u001b[39mCursor(chunk\u001b[39m.\u001b[39mstart)\n\u001b[0;32m-> 3414\u001b[0m     basket \u001b[39m=\u001b[39m uproot\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mTBasket\u001b[39m.\u001b[39;49mModel_TBasket\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m   3415\u001b[0m         chunk,\n\u001b[1;32m   3416\u001b[0m         cursor,\n\u001b[1;32m   3417\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mbasket_num\u001b[39;49m\u001b[39m\"\u001b[39;49m: basket_num},\n\u001b[1;32m   3418\u001b[0m         hasbranches\u001b[39m.\u001b[39;49m_file,\n\u001b[1;32m   3419\u001b[0m         hasbranches\u001b[39m.\u001b[39;49m_file,\n\u001b[1;32m   3420\u001b[0m         branch,\n\u001b[1;32m   3421\u001b[0m     )\n\u001b[1;32m   3422\u001b[0m     original_index \u001b[39m=\u001b[39m range_original_index[(chunk\u001b[39m.\u001b[39mstart, chunk\u001b[39m.\u001b[39mstop)]\n\u001b[1;32m   3423\u001b[0m     \u001b[39mif\u001b[39;00m update_ranges_or_baskets:\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/model.py:837\u001b[0m, in \u001b[0;36mModel.read\u001b[0;34m(cls, chunk, cursor, context, file, selffile, parent, concrete)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mreading\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    833\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_before_read_members(\n\u001b[1;32m    834\u001b[0m         chunk\u001b[39m=\u001b[39mchunk, cursor\u001b[39m=\u001b[39mcursor, context\u001b[39m=\u001b[39mcontext, file\u001b[39m=\u001b[39mfile\n\u001b[1;32m    835\u001b[0m     )\n\u001b[0;32m--> 837\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_members(chunk, cursor, context, file)\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_after_read_members(\n\u001b[1;32m    840\u001b[0m         chunk\u001b[39m=\u001b[39mchunk, cursor\u001b[39m=\u001b[39mcursor, context\u001b[39m=\u001b[39mcontext, file\u001b[39m=\u001b[39mfile\n\u001b[1;32m    841\u001b[0m     )\n\u001b[1;32m    843\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_numbytes(chunk, cursor, context)\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/models/TBasket.py:286\u001b[0m, in \u001b[0;36mModel_TBasket.read_members\u001b[0;34m(self, chunk, cursor, context, file)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m compressed_bytes \u001b[39m!=\u001b[39m uncompressed_bytes:\n\u001b[1;32m    285\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_block_compression_info \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 286\u001b[0m     uncompressed \u001b[39m=\u001b[39m uproot\u001b[39m.\u001b[39;49mcompression\u001b[39m.\u001b[39;49mdecompress(\n\u001b[1;32m    287\u001b[0m         chunk,\n\u001b[1;32m    288\u001b[0m         cursor,\n\u001b[1;32m    289\u001b[0m         {},\n\u001b[1;32m    290\u001b[0m         compressed_bytes,\n\u001b[1;32m    291\u001b[0m         uncompressed_bytes,\n\u001b[1;32m    292\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_block_compression_info,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_block_compression_info \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_block_compression_info)\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_data \u001b[39m=\u001b[39m uncompressed\u001b[39m.\u001b[39mget(\n\u001b[1;32m    296\u001b[0m         \u001b[39m0\u001b[39m,\n\u001b[1;32m    297\u001b[0m         uncompressed_bytes,\n\u001b[1;32m    298\u001b[0m         uproot\u001b[39m.\u001b[39msource\u001b[39m.\u001b[39mcursor\u001b[39m.\u001b[39mCursor(\u001b[39m0\u001b[39m),\n\u001b[1;32m    299\u001b[0m         context,\n\u001b[1;32m    300\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/compression.py:413\u001b[0m, in \u001b[0;36mdecompress\u001b[0;34m(chunk, cursor, context, compressed_bytes, uncompressed_bytes, block_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m block_info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     block_info\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    410\u001b[0m         (decompressor\u001b[39m.\u001b[39mname, block_compressed_bytes, block_uncompressed_bytes)\n\u001b[1;32m    411\u001b[0m     )\n\u001b[0;32m--> 413\u001b[0m uncompressed_bytestring \u001b[39m=\u001b[39m decompressor\u001b[39m.\u001b[39;49mdecompress(\n\u001b[1;32m    414\u001b[0m     data, block_uncompressed_bytes\n\u001b[1;32m    415\u001b[0m )\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uncompressed_bytestring) \u001b[39m!=\u001b[39m block_uncompressed_bytes:\n\u001b[1;32m    418\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    419\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"after successfully decompressing {} blocks, a block of \"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"compressed size {} decompressed to {} bytes, but the \"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m         )\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/site-packages/uproot/compression.py:140\u001b[0m, in \u001b[0;36m_DecompressLZMA.decompress\u001b[0;34m(self, data, uncompressed_bytes)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecompress\u001b[39m(\u001b[39mself\u001b[39m, data, uncompressed_bytes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    139\u001b[0m     lzma \u001b[39m=\u001b[39m uproot\u001b[39m.\u001b[39mextras\u001b[39m.\u001b[39mlzma()\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m lzma\u001b[39m.\u001b[39;49mdecompress(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/lpr/lib/python3.9/lzma.py:342\u001b[0m, in \u001b[0;36mdecompress\u001b[0;34m(data, format, memlimit, filters)\u001b[0m\n\u001b[1;32m    340\u001b[0m decomp \u001b[39m=\u001b[39m LZMADecompressor(\u001b[39mformat\u001b[39m, memlimit, filters)\n\u001b[1;32m    341\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m     res \u001b[39m=\u001b[39m decomp\u001b[39m.\u001b[39;49mdecompress(data)\n\u001b[1;32m    343\u001b[0m \u001b[39mexcept\u001b[39;00m LZMAError:\n\u001b[1;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m results:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#find the Higgs jet idx, dR(gen_Higgs, jet)<0.8 & dR(gen_W_1, jet)<0.8 & dR(gen_W_2, jet)<0.8\n",
    "\n",
    "#collect gen-Higgs information\n",
    "higgs = events_after_cut.GenPart[\n",
    "    (abs(events_after_cut.GenPart.pdgId) == HIGGS_PDGID) * events_after_cut.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "GenHiggsVars = {\n",
    "    f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# collect gen-Higgs children WW information, may not be used, since only Higgs information is needed for the matching\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "GenWWVars = {\n",
    "    # f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1) for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW1Vars = {\n",
    "    # f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\n",
    "    f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1)[:,0] for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW2Vars = {\n",
    "    # f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\n",
    "    f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1)[:,1] for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#collect FatJet information\n",
    "fatjets = events_after_cut.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWWJets = ak.pad_none(fatjets[HWW_match], 1, axis=1)[:, 0] #There can be None object in HWWJets array\n",
    "#tie [pt, eta, phi, mass] together, get new arrary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "filled_pt = pad_val(HWWJets.pt,len(HWWJets.pt),-99)\n",
    "selection_has_HWWjet = filled_pt > 0\n",
    "selection_has_HWWjet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "events_final = events_after_cut[selection_has_HWWjet]\n",
    "len(events_final)\n",
    "events_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it again after the final cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#find the Higgs jet idx, dR(gen_Higgs, jet)<0.8 & dR(gen_W_1, jet)<0.8 & dR(gen_W_2, jet)<0.8\n",
    "\n",
    "#collect gen-Higgs information\n",
    "higgs = events_final.GenPart[\n",
    "    (abs(events_final.GenPart.pdgId) == HIGGS_PDGID) * events_final.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "GenHiggsVars = {\n",
    "    f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# collect gen-Higgs children WW information, may not be used, since only Higgs information is needed for the matching\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "GenWWVars = {\n",
    "    f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW1Vars = {\n",
    "    f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW2Vars = {\n",
    "    f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#collect FatJet information\n",
    "fatjets = events_final.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWWJets = ak.pad_none(fatjets[HWW_match], 1, axis=1)[:, 0] #There can be None object in HWWJets array\n",
    "#tie [pt, eta, phi, mass] together, get new arrary\n",
    "\n",
    "\n",
    "WW_children = WW.children\n",
    "\n",
    "quarks = abs(WW_children.pdgId) <= b_PDGID #get all the 2 Ws daughter PDGID <=5 information\n",
    "print(quarks)\n",
    "\n",
    "# saving 4q 4-vector info\n",
    "Gen4qVars = {\n",
    "    f\"Gen4q{key}\": ak.to_numpy(\n",
    "        ak.fill_none(\n",
    "            ak.pad_none(ak.pad_none(WW_children[var], 2, axis=1, clip=True), 2, axis=2, clip=True),\n",
    "            FILL_NONE_VALUE,\n",
    "        )\n",
    "    )\n",
    "    for (var, key) in skim_vars.items()\n",
    "}\n",
    "len(Gen4qVars[\"Gen4qPt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### four vector for HWW jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# four vector for HWW jet\n",
    "higgs_jet_4vec_H3q4q = np.array(np.stack((np.array(HWWJets.pt), np.array(HWWJets.eta),np.array(HWWJets.phi),np.array(HWWJets.mass)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(higgs_jet_4vec_H3q4q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next eta-phi for 4 quarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Finally construct the eta-phi array\n",
    "eta_4q = Gen4qVars[\"Gen4qEta\"].reshape(Gen4qVars[\"Gen4qEta\"].shape[0], -1)\n",
    "phi_4q = Gen4qVars[\"Gen4qPhi\"].reshape(Gen4qVars[\"Gen4qPhi\"].shape[0], -1)\n",
    "gen_parts_eta_phi_H3q4q_4q = np.array(np.dstack((eta_4q,phi_4q)))\n",
    "# can do test like : gen_parts_eta_phi[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#count the number of quarks inside the AK8 jet, require 3 or 4 quarks.\n",
    "def count_quarks_in_jets(jet_4vec, gen_parts_eta_phi, delta_r_cut=0.8):\n",
    "    num_jets = len(jet_4vec)\n",
    "    num_quarks_in_jets = np.zeros(num_jets, dtype=int)\n",
    "\n",
    "    for i in range(num_jets):\n",
    "        jet_eta, jet_phi = jet_4vec[i][1], jet_4vec[i][2]\n",
    "\n",
    "        quark_eta_phi = gen_parts_eta_phi[i]\n",
    "        quark_eta, quark_phi = quark_eta_phi[:, 0], quark_eta_phi[:, 1]\n",
    "\n",
    "        delta_eta = jet_eta - quark_eta\n",
    "        delta_phi = jet_phi - quark_phi\n",
    "\n",
    "        delta_r_squared = delta_eta**2 + delta_phi**2\n",
    "        quarks_in_jet = np.sqrt(delta_r_squared) < delta_r_cut\n",
    "\n",
    "        num_quarks_in_jets[i] = np.sum(quarks_in_jet)\n",
    "\n",
    "    return num_quarks_in_jets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result_4q = count_quarks_in_jets(higgs_jet_4vec_H3q4q, gen_parts_eta_phi_H3q4q_4q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "H3q4q_cut = (result_4q >= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FatJetPFCands 4-vector, up to 150 length to suit the input of Oz's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# first get the jet_idx HWW jet, each event has one jet_idx\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWW_match_padded = pad_val(HWW_match,3,False,1,True) #pad the array with False value\n",
    "HWW_jet_idx = np.argmax(HWW_match_padded,axis = 1) #the jet index in each jet which is true HWW jet\n",
    "# then get all the FatJetPFCands according to the jet_idx, and get PF_idx\n",
    "HWW_FatJetPFCands = (events_final.FatJetPFCands.jetIdx == HWW_jet_idx)\n",
    "HWW_FatJetPFCands_pFCandsIdx = events_final.FatJetPFCands.pFCandsIdx[HWW_FatJetPFCands]\n",
    "# at last, get PFCands 4-vector according to the PF_idx in last step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pt_array =   ak.Array(events_final.PFCands.pt)\n",
    "eta_array =  ak.Array(events_final.PFCands.eta)\n",
    "phi_array =  ak.Array(events_final.PFCands.phi)\n",
    "mass_array = ak.Array(events_final.PFCands.mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_pt =  pt_array[HWW_FatJetPFCands_pFCandsIdx]\n",
    "selected_eta = eta_array[HWW_FatJetPFCands_pFCandsIdx]\n",
    "selected_phi = phi_array[HWW_FatJetPFCands_pFCandsIdx]\n",
    "selected_mass = mass_array[HWW_FatJetPFCands_pFCandsIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_pt_padded = pad_val(selected_pt,150,0,1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_eta_padded = pad_val(selected_eta,150,0,1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_phi_padded = pad_val(selected_phi,150,0,1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_mass_padded = pad_val(selected_mass,150,0,1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Construct (px,py,pz,E) using (pt,eta,phi,mass) information as the input\n",
    "pf_cands_px = selected_pt_padded * np.cos(selected_phi_padded)\n",
    "pf_cands_py = selected_pt_padded * np.sin(selected_phi_padded)\n",
    "pf_cands_pz = selected_pt_padded * np.sinh(selected_eta_padded)\n",
    "pf_cands_E = np.sqrt(pf_cands_px**2 + pf_cands_py**2 + pf_cands_pz**2 + selected_mass_padded**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pf_cands_pxpypzE_4q = np.dstack((pf_cands_px,pf_cands_py,pf_cands_pz,pf_cands_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# do final cut using H4q3q selection:\n",
    "gen_parts_eta_phi_H3q4q_4q = gen_parts_eta_phi_H3q4q_4q[H3q4q_cut]\n",
    "pf_cands_pxpypzE_4q = pf_cands_pxpypzE_4q[H3q4q_cut]\n",
    "higgs_jet_4vec_H3q4q = higgs_jet_4vec_H3q4q[H3q4q_cut]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next compute tagger score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eventsScoreFatjet = events_final\n",
    "tagger_scores = eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWev0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWev1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWmv0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWmv1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWq0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWq1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWq2c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWqq0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWqq1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWqq2c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauev0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauev1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauhv0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauhv1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtaumv0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtaumv1c\n",
    "\n",
    "fatjets = events_final.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "\n",
    "HWWJets_tagger_score_3q4q = ak.pad_none(tagger_scores[HWW_match], 1, axis=1)[:, 0]\n",
    "\n",
    "HWWJets_tagger_score_3q4q = HWWJets_tagger_score_3q4q[H3q4q_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(HWWJets_tagger_score_3q4q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "H3q4q_len = len(HWWJets_tagger_score_3q4q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate SFs and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '')\n",
    "sys.path.append(\"/home/pku/zhaoyz/Higgs/LundReweighting\")\n",
    "from utils.LundReweighter import *\n",
    "from utils.Utils import *\n",
    "\"\"\" An example how to use the Lund Plane reweighting  code \"\"\"\n",
    "\n",
    "######################## Setup \n",
    "\n",
    "#Input file \n",
    "fname = \"/home/pku/zhaoyz/Higgs/LundReweighting/data/example_signal.h5\"\n",
    "#File containing data/MC Lund Plane ratio\n",
    "f_ratio_name = '/home/pku/zhaoyz/Higgs/LundReweighting/data/ratio_2018.root'\n",
    "\n",
    "f_sig = h5py.File(fname, \"r\")\n",
    "f_ratio = ROOT.TFile.Open(f_ratio_name)\n",
    "\n",
    "#Class to help read input dataset, \"Dataset\" class defined in Utils.py\n",
    "# d = Dataset(f_sig, dtype = 1)\n",
    "# d.compute_obs() #there may be some dedicated variables inside the .h5 file\n",
    "\n",
    "#The cut we will compute a SF for 'tau21 < 0.34'\n",
    "tag_obs = 'tau21'\n",
    "score_thresh = 0.975\n",
    "\n",
    "\n",
    "#nominal data/MC Lund plane ratio (3d histogram)\n",
    "h_ratio = f_ratio.Get(\"ratio_nom\")\n",
    "#systematic variations\n",
    "h_ratio_sys_up = f_ratio.Get(\"ratio_sys_tot_up\")\n",
    "h_ratio_sys_down = f_ratio.Get(\"ratio_sys_tot_down\")\n",
    "#MC ratio of b to light quarks\n",
    "b_light_ratio = f_ratio.Get(\"h_bl_ratio\")\n",
    "\n",
    "\n",
    "#directory of pt extrapolation fits\n",
    "f_ratio.cd('pt_extrap')\n",
    "rdir = ROOT.gDirectory #get the present working directory and give it to rdir\n",
    "\n",
    "#Main class for reweighting utilities\n",
    "LP_rw = LundReweighter(pt_extrap_dir = rdir)\n",
    "\n",
    "max_evts = H3q4q_len\n",
    "\n",
    "# score = getattr(d, tag_obs)[:max_evts]\n",
    "score_cut = ((HWWJets_tagger_score_3q4q >= 0.8) & (HWWJets_tagger_score_3q4q <= 0.975))\n",
    "# score_cut = (HWWJets_tagger_score > 0.975)\n",
    "score_cut = score_cut[:max_evts]\n",
    "\n",
    "\n",
    "#Number of toys for statistical and pt extrapolation uncertainties\n",
    "nToys = 100\n",
    "#Noise vectors used to to generate the toys\n",
    "#NOTE the same vector has to be used for the whole sample/signal file for the toys to be consistent \n",
    "rand_noise = np.random.normal(size = (nToys, h_ratio.GetNbinsX(), h_ratio.GetNbinsY(), h_ratio.GetNbinsZ()))\n",
    "pt_rand_noise = np.random.normal(size = (nToys, h_ratio.GetNbinsY(), h_ratio.GetNbinsZ(), 3))\n",
    "\n",
    "\n",
    "################### Compute reweighting factors\n",
    "\n",
    "#PF candidates in the AK8 jet\n",
    "# pf_cands = d.get_masked(\"jet1_PFCands\").astype(np.float64)[:max_evts]\n",
    "pf_cands = pf_cands_pxpypzE_4q[:max_evts]\n",
    "#Generator level quarks from hard process\n",
    "\n",
    "# gen_parts = d.get_masked('gen_info')[:max_evts]\n",
    "gen_parts_eta_phi = gen_parts_eta_phi_H3q4q_4q[:max_evts]\n",
    "# gen_parts_pdg_ids = gen_parts[:,:,3]\n",
    "\n",
    "B_PDG_ID = 5\n",
    "\n",
    "# ak8_jets = d.get_masked('jet_kinematics')[:max_evts][:,2:6].astype(np.float64)\n",
    "ak8_jets = higgs_jet_4vec_H3q4q[:max_evts]\n",
    "\n",
    "#Nominal event weights of the MC, assume every event is weight '1' for this example\n",
    "weights_nom = np.ones(max_evts)\n",
    "\n",
    "LP_weights = []\n",
    "LP_weights_sys_up = []\n",
    "LP_weights_sys_down = []\n",
    "stat_smeared_weights = []\n",
    "pt_smeared_weights = []\n",
    "b_weights_up = []\n",
    "b_weights_down = []\n",
    "bad_matches = []\n",
    "\n",
    "\n",
    "for i,cands in enumerate(pf_cands):\n",
    "    # if i == 4: break\n",
    "    # print(\"now processing:\",i)\n",
    "    #Get the subjets, splittings and checking matching based on PF candidates in the jet and gen-level quarks\n",
    "    subjets, splittings, bad_match, deltaRs = LP_rw.get_splittings_and_matching(cands, gen_parts_eta_phi[i], ak8_jets[i])\n",
    "    # print(bad_match)\n",
    "    # print(deltaRs)\n",
    "    #Gets the nominal LP reweighting factor for this event and statistical + pt extrapolation toys\n",
    "    LP_weight, stat_smeared_weight, pt_smeared_weight = LP_rw.reweight_lund_plane(h_rw = h_ratio, subjets = subjets, splittings = splittings,\n",
    "            rand_noise = rand_noise, pt_rand_noise = pt_rand_noise, )\n",
    "    #Now get systematic variations\n",
    "    LP_weight_sys_up,_,_ = LP_rw.reweight_lund_plane(h_rw = h_ratio_sys_up, subjets = subjets, splittings = splittings)\n",
    "    LP_weight_sys_down,_,_ = LP_rw.reweight_lund_plane(h_rw = h_ratio_sys_down, subjets = subjets, splittings = splittings)\n",
    "\n",
    "    LP_weights.append(LP_weight)\n",
    "    stat_smeared_weights.append(stat_smeared_weight)\n",
    "    pt_smeared_weights.append(pt_smeared_weight)\n",
    "\n",
    "    LP_weights_sys_up.append(LP_weight_sys_up)\n",
    "    LP_weights_sys_down.append(LP_weight_sys_down)\n",
    "    bad_matches.append(bad_match)\n",
    "\n",
    "\n",
    "\n",
    "############### Normalize weights to preserve normalization of the MC sample\n",
    "\n",
    "#The nominal Lund Plane correction event weights\n",
    "LP_weights = LP_rw.normalize_weights(LP_weights) * weights_nom \n",
    "\n",
    "#Toy variations for stat and pt uncertainties\n",
    "stat_smeared_weights = LP_rw.normalize_weights(stat_smeared_weights) * weights_nom.reshape(max_evts, 1)\n",
    "pt_smeared_weights = LP_rw.normalize_weights(pt_smeared_weights) * weights_nom.reshape(max_evts,1)\n",
    "\n",
    "#Systematic up/down variations\n",
    "LP_weights_sys_up = LP_rw.normalize_weights(LP_weights_sys_up) * weights_nom\n",
    "LP_weights_sys_down = LP_rw.normalize_weights(LP_weights_sys_down) * weights_nom\n",
    "\n",
    "############### Compute efficiences and uncertainties\n",
    "\n",
    "\n",
    "#Efficiency of the cut in nominal MC\n",
    "eff_nom = np.average(score_cut, weights = weights_nom) #TODO\n",
    "\n",
    "#Efficiency of the cut after the Lund Plane reweighting\n",
    "eff_rw = np.average(score_cut, weights = LP_weights)\n",
    "\n",
    "#Nominal 'scale factor'\n",
    "SF = eff_rw / eff_nom\n",
    "\n",
    "print(\"Nominal efficiency %.3f, Corrected efficiency %.3f, SF (corrected / nom) %.3f\" % (eff_nom, eff_rw, SF))\n",
    "\n",
    "#NOTE, better to use corrected efficiency computed separately for each sample rather than a single 'SF'\n",
    "\n",
    "\n",
    "#Compute efficiency for each of the stat/pt toys\n",
    "eff_toys = []\n",
    "pt_eff_toys = []\n",
    "for i in range(nToys):\n",
    "    eff = np.average(score_cut, weights = stat_smeared_weights[:,i])\n",
    "    eff_toys.append(eff)\n",
    "\n",
    "    eff1 = np.average(score_cut, weights = pt_smeared_weights[:,i])\n",
    "    pt_eff_toys.append(eff1)\n",
    "\n",
    "#Compute stat and pt uncertainty based on variation in the toys\n",
    "toys_mean = np.mean(eff_toys)\n",
    "toys_std = np.std(eff_toys)\n",
    "pt_toys_mean = np.mean(pt_eff_toys)\n",
    "pt_toys_std = np.std(pt_eff_toys)\n",
    "\n",
    "eff_stat_unc = (abs(toys_mean - eff_rw)  + toys_std) \n",
    "eff_pt_unc = (abs(pt_toys_mean - eff_rw) + pt_toys_std)\n",
    "\n",
    "print(\"Stat variation toys eff. avg %.3f, std dev %.3f\" % (toys_mean, toys_std))\n",
    "print(\"Pt variation toys eff. avg %.3f, std dev %.3f\" % (pt_toys_mean, pt_toys_std))\n",
    "\n",
    "\n",
    "#Compute difference in efficiency due to weight variations as uncertainty\n",
    "def get_uncs(score_cut, weights_up, weights_down, eff_baseline):\n",
    "    eff_up =  np.average(score_cut, weights = weights_up)\n",
    "    eff_down =  np.average(score_cut, weights = weights_down)\n",
    "\n",
    "    unc_up = eff_up - eff_baseline\n",
    "    unc_down = eff_down - eff_baseline \n",
    "    return unc_up, unc_down\n",
    "\n",
    "\n",
    "#Compute efficiency of systematic variations\n",
    "sys_unc_up, sys_unc_down = get_uncs(score_cut, LP_weights_sys_up, LP_weights_sys_down, eff_rw)\n",
    "# b_unc_up, b_unc_down = get_uncs(score_cut, b_weights_up, b_weights_down, eff_rw)\n",
    "\n",
    "\n",
    "#matching uncertainty, taken as a fractional uncertainty on efficiency\n",
    "bad_match_frac = np.mean(bad_matches)\n",
    "bad_match_unc = bad_match_frac * eff_rw\n",
    "\n",
    "\n",
    "############ Results\n",
    "print(\"\\n\\nCalibrated efficiency  is %.3f +/- %.3f  (stat) +/- %.3f (pt) +/- %.3f/%.3f (sys)+/- %.3f (matching)  \\n\\n\"  % \n",
    "        (eff_rw, eff_stat_unc, eff_pt_unc, sys_unc_up, sys_unc_down, bad_match_unc))\n",
    "\n",
    "#next compute the uncertainty about SFs\n",
    "\n",
    "#Efficiency of the cut in nominal MC\n",
    "eff_nom = np.average(score_cut, weights = weights_nom) #TODO\n",
    "\n",
    "#Efficiency of the cut after the Lund Plane reweighting\n",
    "eff_rw = np.average(score_cut, weights = LP_weights)\n",
    "\n",
    "#Nominal 'scale factor'\n",
    "print(\"Now perform SFs information\")\n",
    "SF = eff_rw / eff_nom\n",
    "\n",
    "print(\"SF (corrected / nom) %.3f\" % (SF))\n",
    "\n",
    "#propagate statistical and pt extrapolation uncertainties to SF\n",
    "SF_stat_unc = (abs(toys_mean - eff_rw)  + toys_std) /eff_nom\n",
    "SF_pt_unc = (abs(pt_toys_mean - eff_rw) + pt_toys_std) /eff_nom\n",
    "\n",
    "#propagate systemetic uncertainty to SF\n",
    "eff_sys_up =  np.average(score_cut, weights = LP_weights_sys_up)\n",
    "eff_sys_down =  np.average(score_cut, weights = LP_weights_sys_down)\n",
    "\n",
    "sys_unc_up = abs(eff_rw - eff_sys_up)\n",
    "sys_unc_down = abs(eff_rw - eff_sys_down)\n",
    "\n",
    "SF_sys_unc_up = sys_unc_up/eff_nom\n",
    "SF_sys_unc_down = sys_unc_down/eff_nom\n",
    "\n",
    "#calculate bad matching uncertainty directly\n",
    "SF_match_unc = bad_match_frac * SF\n",
    "\n",
    "print(\"\\n\\nSF is %.3f +/-%.3f(stat) +/-%.3f(pt) +%.3f/-%.3f(sys) +/-%.3f(match) \\n\\n\"  % (SF, SF_stat_unc, SF_pt_unc, sys_unc_up, sys_unc_down, SF_match_unc))\n",
    "f_ratio.Close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the tagger distribution about H3q4q jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from cycler import cycler\n",
    "max_evts = H3q4q_len\n",
    "#implement CMS plot style functions\n",
    "use_helvet = False ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax=plt.gca()\n",
    "plt.grid()\n",
    "hep.cms.label(data=False, year=\"2018\", ax=ax, fontname='sans-serif')\n",
    "%matplotlib inline\n",
    "#step1: plot \n",
    "\n",
    "# plt.hist(eventsEventsID3Prongs4Prongs['HqqqqVsQcdTop'], bins=20, range=(0,1), histtype='step', label='before reweighting',density=True);\n",
    "# plt.hist(eventsEventsID3Prongs4Prongs['HqqqqVsQcdTop'], bins=20, range=(0,1), histtype='step', label='after reweighting', weights=eventsEventsID3Prongs4Prongs[\"LP_weight\"],density=True);\n",
    "nbins, x_min, x_max = 20, 0, 1.0\n",
    "hist_before = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "hist_before.fill(HWWJets_tagger_score_3q4q[:max_evts])\n",
    "hist_before_value = hist_before.view().value\n",
    "hist_before_err = np.sqrt(hist_before.view().variance)\n",
    "hist_after = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "hist_after.fill(HWWJets_tagger_score_3q4q[:max_evts],weight=LP_weights[:max_evts])\n",
    "hist_after_value = hist_after.view().value\n",
    "hist_after_err = np.sqrt(hist_after.view().variance)\n",
    "bins = hist_before.axes[0].edges\n",
    "\n",
    "\n",
    "hep.histplot(hist_before_value,    bins=bins, yerr=hist_before_err, label= 'before Lund Plane reweighting', lw = 2,edges = False, histtype=\"step\")\n",
    "hep.histplot(hist_after_value,     bins=bins, yerr=hist_after_err,  label= 'after Lund Plane reweighting', lw = 2,edges = False, histtype=\"step\")\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',frameon=False,fontsize=20)\n",
    "y_min,y_max = plt.gca().get_ylim()\n",
    "plt.text(0.08, 0.83*y_max, \"ggF, only for H3q4q\", fontsize=20)\n",
    "# plt.xlabel(r'$H_{qqqq} / (H_{qqqq} + QCD + Top)$')\n",
    "plt.xlabel(r'HWWvs(all background) tagger score', fontsize=20, ha='right', x=1)\n",
    "plt.ylabel('Events(No xs-weighted)',fontsize=20, ha='right', y=1)\n",
    "plt.savefig(f\"TaggerDistribution_2018_ggF_H4q3q_all.pdf\", bbox_inches='tight')\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next part is to re-calculate all the steps but focus on Hlvqq jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#start from here, have done all pre-selection, as well as H-->WW decay selection\n",
    "filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Then do other test:\n",
    "selection = PackedSelection() #initialize a new object\n",
    "isData = False\n",
    "signGenWeights = None if isData else np.sign(filtered_events[\"genWeight\"]) #get genWeight sign, because only the sign matters\n",
    "n_events = len(filtered_events) if isData else int(np.sum(signGenWeights)) #events number for MC events should be the sum of \"sign\"\n",
    "selection = PackedSelection() #initialize a new object\n",
    "\n",
    "cutflow = {}\n",
    "# cutflow[\"all\"] = len(events) #shouldn't be n_events?\n",
    "cutflow[\"all\"] = n_events\n",
    "# finding the gen higgs\n",
    "higgs = filtered_events.GenPart[\n",
    "    (abs(filtered_events.GenPart.pdgId) == HIGGS_PDGID) * filtered_events.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "# saving 4-vector info\n",
    "GenHiggsVars = {f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()}\n",
    "\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# saving whether H->bb or H->VV\n",
    "GenHiggsVars[\"GenHiggsChildren\"] = abs(higgs_children.pdgId[:, :, 0]).to_numpy()\n",
    "\n",
    "# finding WW children\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "\n",
    "# Hbb = higgs[ak.sum(is_bb, axis=2) == 2]\n",
    "HWW = higgs[ak.sum(is_WW, axis=2) == 2]\n",
    "\n",
    "# checking that there are 2 b's and 2 V's\n",
    "has_WW = ak.sum(ak.flatten(is_WW, axis=2), axis=1) == 2\n",
    "\n",
    "add_selection(\n",
    "    \"HtoWW\",\n",
    "    has_WW, \n",
    "    selection, \n",
    "    cutflow, \n",
    "    False, \n",
    "    signGenWeights)\n",
    "# print(selection_all_q)\n",
    "\n",
    "\n",
    "\n",
    "# saving WW 4-vector info\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "#for normal ggF, VBF HWW signal\n",
    "GenWWVars = {\n",
    "    f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#for ttHnonbb HWW signal, because there may not be H-->WW events\n",
    "# GenWWVars = {\n",
    "#     f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1) for (var, key) in skim_vars.items()\n",
    "#     }\n",
    "\n",
    "# checking that each W has 2 q children, so finally the HWW jet will be H4q or H3q jet\n",
    "WW_children = WW.children\n",
    "\n",
    "quarks = abs(WW_children.pdgId) <= b_PDGID #get all the 2 Ws daughter PDGID <=5 information\n",
    "leptons = abs(WW_children.pdgId) >= ELE_PDGID\n",
    "\n",
    "selection_all_q = ak.all(ak.all(quarks, axis=2), axis=1) #check if all the children of 2 Ws are quarks or not\n",
    "selection_all_lep = ak.all(ak.all(leptons, axis=2), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selection_semilep = (~selection_all_q) & (~selection_all_lep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "add_selection(\n",
    "    \"WW decays to lvqq\",\n",
    "    selection_semilep, \n",
    "    selection, \n",
    "    cutflow, \n",
    "    False, \n",
    "    signGenWeights)\n",
    "# print(selection_all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store the PFCands, GenEtaPhi, Higgs candidate AK8 jet 4-vector information for Lund Plane use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "events_after_cut = filtered_events[selection.all(*selection.names)]\n",
    "events_after_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#find the Higgs jet idx, dR(gen_Higgs, jet)<0.8 & dR(gen_W_1, jet)<0.8 & dR(gen_W_2, jet)<0.8\n",
    "\n",
    "#collect gen-Higgs information\n",
    "higgs = events_after_cut.GenPart[\n",
    "    (abs(events_after_cut.GenPart.pdgId) == HIGGS_PDGID) * events_after_cut.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "GenHiggsVars = {\n",
    "    f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# collect gen-Higgs children WW information, may not be used, since only Higgs information is needed for the matching\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "GenWWVars = {\n",
    "    # f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1) for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW1Vars = {\n",
    "    # f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\n",
    "    f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1)[:,0] for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW2Vars = {\n",
    "    # f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\n",
    "    f\"GenWW{key}\": pad_val(WW[var], 2, FILL_NONE_VALUE, axis=1)[:,1] for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#collect FatJet information\n",
    "fatjets = events_after_cut.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWWJets = ak.pad_none(fatjets[HWW_match], 1, axis=1)[:, 0] #There can be None object in HWWJets array\n",
    "#tie [pt, eta, phi, mass] together, get new arrary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "filled_pt = pad_val(HWWJets.pt,len(HWWJets.pt),-99)\n",
    "selection_has_HWWjet = filled_pt > 0\n",
    "selection_has_HWWjet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "events_final = events_after_cut[selection_has_HWWjet]\n",
    "len(events_final)\n",
    "events_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it again after the final cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#find the Higgs jet idx, dR(gen_Higgs, jet)<0.8 & dR(gen_W_1, jet)<0.8 & dR(gen_W_2, jet)<0.8\n",
    "\n",
    "#collect gen-Higgs information\n",
    "higgs = events_final.GenPart[\n",
    "    (abs(events_final.GenPart.pdgId) == HIGGS_PDGID) * events_final.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "GenHiggsVars = {\n",
    "    f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# collect gen-Higgs children WW information, may not be used, since only Higgs information is needed for the matching\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "GenWWVars = {\n",
    "    f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW1Vars = {\n",
    "    f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW2Vars = {\n",
    "    f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#collect FatJet information\n",
    "fatjets = events_final.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWWJets = ak.pad_none(fatjets[HWW_match], 1, axis=1)[:, 0] #There can be None object in HWWJets array\n",
    "#tie [pt, eta, phi, mass] together, get new arrary\n",
    "\n",
    "\n",
    "WW_children = WW.children\n",
    "\n",
    "quarks = abs(WW_children.pdgId) <= b_PDGID #get all the 2 Ws daughter PDGID <=5 information\n",
    "print(quarks)\n",
    "\n",
    "# saving 4q 4-vector info\n",
    "Gen4qVars = {\n",
    "    f\"Gen4q{key}\": ak.to_numpy(\n",
    "        ak.fill_none(\n",
    "            ak.pad_none(ak.pad_none(WW_children[var], 2, axis=1, clip=True), 2, axis=2, clip=True),\n",
    "            FILL_NONE_VALUE,\n",
    "        )\n",
    "    )\n",
    "    for (var, key) in skim_vars.items()\n",
    "}\n",
    "len(Gen4qVars[\"Gen4qPt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "had_w_sel = np.all(np.abs(WW_children.pdgId) <= 5 , axis =2 )\n",
    "had_ws = ak.flatten(WW[had_w_sel])\n",
    "had_ws_children = had_ws.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sel_norm = ~np.all((~had_w_sel),axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sel_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some strange bugs occur, so do it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "events_final = events_final[sel_norm]\n",
    "len(events_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#find the Higgs jet idx, dR(gen_Higgs, jet)<0.8 & dR(gen_W_1, jet)<0.8 & dR(gen_W_2, jet)<0.8\n",
    "\n",
    "#collect gen-Higgs information\n",
    "higgs = events_final.GenPart[\n",
    "    (abs(events_final.GenPart.pdgId) == HIGGS_PDGID) * events_final.GenPart.hasFlags(GEN_FLAGS)\n",
    "]\n",
    "GenHiggsVars = {\n",
    "    f\"GenHiggs{key}\": higgs[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "higgs_children = higgs.children\n",
    "\n",
    "# collect gen-Higgs children WW information, may not be used, since only Higgs information is needed for the matching\n",
    "is_WW = abs(higgs_children.pdgId) == W_PDGID\n",
    "WW = ak.flatten(higgs_children[is_WW], axis=2)\n",
    "\n",
    "GenWWVars = {\n",
    "    f\"GenWW{key}\": WW[var].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW1Vars = {\n",
    "    f\"GenWW{key}\": WW[var][:,0].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "GenW2Vars = {\n",
    "    f\"GenWW{key}\": WW[var][:,1].to_numpy() for (var, key) in skim_vars.items()\n",
    "    }\n",
    "\n",
    "#collect FatJet information\n",
    "fatjets = events_final.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWWJets = ak.pad_none(fatjets[HWW_match], 1, axis=1)[:, 0] #There can be None object in HWWJets array\n",
    "#tie [pt, eta, phi, mass] together, get new arrary\n",
    "\n",
    "\n",
    "WW_children = WW.children\n",
    "\n",
    "quarks = abs(WW_children.pdgId) <= b_PDGID #get all the 2 Ws daughter PDGID <=5 information\n",
    "print(quarks)\n",
    "\n",
    "# saving 4q 4-vector info\n",
    "Gen4qVars = {\n",
    "    f\"Gen4q{key}\": ak.to_numpy(\n",
    "        ak.fill_none(\n",
    "            ak.pad_none(ak.pad_none(WW_children[var], 2, axis=1, clip=True), 2, axis=2, clip=True),\n",
    "            FILL_NONE_VALUE,\n",
    "        )\n",
    "    )\n",
    "    for (var, key) in skim_vars.items()\n",
    "}\n",
    "len(Gen4qVars[\"Gen4qPt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "had_w_sel = np.all(np.abs(WW_children.pdgId) <= 5 , axis =2 )\n",
    "had_ws = ak.flatten(WW[had_w_sel])\n",
    "had_ws_children = had_ws.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_w_sel = np.all(np.abs(WW_children.pdgId) > 10 , axis =2 )\n",
    "lep_ws = ak.flatten(WW[lep_w_sel])\n",
    "lep_ws_children = lep_ws.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "had_ws_children.pdgId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_ws_children.pdgId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Gen2qVars = {\n",
    "    f\"Gen2q{key}\": ak.to_numpy(\n",
    "        ak.fill_none(\n",
    "            ak.pad_none(had_ws_children[var], 2, axis=1, clip=True),\n",
    "            FILL_NONE_VALUE,\n",
    "        )\n",
    "    )\n",
    "    for (var, key) in skim_vars.items()\n",
    "}\n",
    "len(Gen2qVars[\"Gen2qPt\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "GenlepVars = {\n",
    "    f\"Genlep{key}\": ak.to_numpy(\n",
    "        lep_ws_children[:,0][var])\n",
    "    for (var, key) in skim_vars.items()\n",
    "}\n",
    "len(GenlepVars[\"GenlepPt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### four vector for HWW jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# four vector for HWW jet\n",
    "higgs_jet_4vec_Hlvqq = np.array(np.stack((np.array(HWWJets.pt), np.array(HWWJets.eta),np.array(HWWJets.phi),np.array(HWWJets.mass)), axis=1))\n",
    "higgs_jet_4vec_Hlvqq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(higgs_jet_4vec_Hlvqq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next for eta-phi for 4 quarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#prepare eta, phi array only for 2q, used for Lund Plane reweighting\n",
    "#since it only takes quarks gen-level 4-vector as input\n",
    "eta_2q = Gen2qVars[\"Gen2qEta\"]\n",
    "phi_2q = Gen2qVars[\"Gen2qPhi\"]\n",
    "gen_parts_eta_phi_Hlvqq_2q = np.array(np.dstack((eta_2q,phi_2q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eta_2q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#prepare eta, phi array for 2q + lep, to do gen-matching of the jet\n",
    "eta = np.concatenate([Gen2qVars[\"Gen2qEta\"], GenlepVars[\"GenlepEta\"][:, np.newaxis]], axis=1)\n",
    "phi = np.concatenate([Gen2qVars[\"Gen2qPhi\"], GenlepVars[\"GenlepPhi\"][:, np.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gen_parts_eta_phi_HWW = np.array(np.dstack((eta,phi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result_lvqq = count_quarks_in_jets(higgs_jet_4vec_Hlvqq, gen_parts_eta_phi_HWW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Hlvqq_cut = (result_lvqq >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.sum(Hlvqq_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FatJetPFCands 4-vector, up to 150 length to suit the input of Oz's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# first get the jet_idx HWW jet, each event has one jet_idx\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "HWW_match_padded = pad_val(HWW_match,3,False,1,True) #pad the array with False value\n",
    "HWW_jet_idx = np.argmax(HWW_match_padded,axis = 1) #the jet index in each jet which is true HWW jet\n",
    "# then get all the FatJetPFCands according to the jet_idx, and get PF_idx\n",
    "HWW_FatJetPFCands = (events_final.FatJetPFCands.jetIdx == HWW_jet_idx)\n",
    "HWW_FatJetPFCands_pFCandsIdx = events_final.FatJetPFCands.pFCandsIdx[HWW_FatJetPFCands]\n",
    "# at last, get PFCands 4-vector according to the PF_idx in last step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pt_array =   ak.Array(events_final.PFCands.pt)\n",
    "eta_array =  ak.Array(events_final.PFCands.eta)\n",
    "phi_array =  ak.Array(events_final.PFCands.phi)\n",
    "mass_array = ak.Array(events_final.PFCands.mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to clean PFCands with dR(l,pf)<0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_eta = GenlepVars[\"GenlepEta\"]\n",
    "lep_phi = GenlepVars[\"GenlepPhi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#this is because the length of PFCands can be up to 409, so we pad to target = 500\n",
    "pf_eta = pad_val(eta_array, target = 500, axis = 1, value = 0)\n",
    "pf_phi = pad_val(phi_array, target = 500, axis = 1, value = 0)\n",
    "pf_pt = pad_val(pt_array, target = 500, axis = 1, value = 0)\n",
    "pf_mass = pad_val(mass_array, target = 500, axis = 1, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_eta_reshaped = lep_eta.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_eta_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lep_phi_reshaped = lep_phi.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "delta_eta = lep_eta_reshaped - pf_eta\n",
    "delta_phi = lep_phi_reshaped - pf_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "delta_r = np.sqrt(delta_eta**2 + delta_phi**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pf_eta_rm_lep = np.copy(pf_eta)\n",
    "pf_phi_rm_lep = np.copy(pf_phi)\n",
    "pf_pt_rm_lep = np.copy(pf_pt)\n",
    "pf_mass_rm_lep = np.copy(pf_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pf_eta_rm_lep[delta_r<0.2] = 0.0\n",
    "pf_phi_rm_lep[delta_r<0.2] = 0.0\n",
    "pf_pt_rm_lep[delta_r<0.2] = 0.0\n",
    "pf_mass_rm_lep[delta_r<0.2] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.max(HWW_FatJetPFCands_pFCandsIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "selected_eta  = ak.Array(pf_eta_rm_lep)[HWW_FatJetPFCands_pFCandsIdx]\n",
    "selected_phi  = ak.Array(pf_phi_rm_lep)[HWW_FatJetPFCands_pFCandsIdx]\n",
    "selected_pt   = ak.Array(pf_pt_rm_lep)[HWW_FatJetPFCands_pFCandsIdx]\n",
    "selected_mass = ak.Array(pf_mass_rm_lep)[HWW_FatJetPFCands_pFCandsIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(selected_eta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# pad the selected 4-vec array up to length of 150 to match the Lund Plane input\n",
    "selected_pt_padded = pad_val(selected_pt,150,0,1,True)\n",
    "selected_eta_padded = pad_val(selected_eta,150,0,1,True)\n",
    "selected_phi_padded = pad_val(selected_phi,150,0,1,True)\n",
    "selected_mass_padded = pad_val(selected_mass,150,0,1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pf_cands_px = selected_pt_padded * np.cos(selected_phi_padded)\n",
    "pf_cands_py = selected_pt_padded * np.sin(selected_phi_padded)\n",
    "pf_cands_pz = selected_pt_padded * np.sinh(selected_eta_padded)\n",
    "pf_cands_E = np.sqrt(pf_cands_px**2 + pf_cands_py**2 + pf_cands_pz**2 + selected_mass_padded**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pf_cands_pxpypzE_lvqq = np.dstack((pf_cands_px,pf_cands_py,pf_cands_pz,pf_cands_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(len(pf_cands_pxpypzE_lvqq[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final check the input information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#not all these 3 input array are without Hlvqq_cut\n",
    "print(len(gen_parts_eta_phi_Hlvqq_2q))\n",
    "print(len(pf_cands_pxpypzE_lvqq))\n",
    "print(len(higgs_jet_4vec_Hlvqq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gen_parts_eta_phi_Hlvqq_2q = gen_parts_eta_phi_Hlvqq_2q[Hlvqq_cut]\n",
    "pf_cands_pxpypzE_lvqq = pf_cands_pxpypzE_lvqq[Hlvqq_cut]\n",
    "higgs_jet_4vec_Hlvqq = higgs_jet_4vec_Hlvqq[Hlvqq_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#not all these 3 input array are with Hlvqq_cut\n",
    "print(len(gen_parts_eta_phi_Hlvqq_2q))\n",
    "print(len(pf_cands_pxpypzE_lvqq))\n",
    "print(len(higgs_jet_4vec_Hlvqq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eventsScoreFatjet = events_final\n",
    "tagger_scores = eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWev0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWev1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWmv0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWmv1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWq0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWq1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWq2c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWqq0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWqq1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWqq2c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauev0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauev1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauhv0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtauhv1c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtaumv0c + eventsScoreFatjet.FatJet.inclParTMDV1_probHWqqWtaumv1c\n",
    "\n",
    "fatjets = events_final.FatJet\n",
    "HWW = ak.pad_none(higgs, 1, axis=1, clip=True)[:, 0] #because it's a 2D array\n",
    "WWdr = fatjets[:, :3].delta_r(HWW) #here use 3 because we have up to 3 AK8 jets, use ak.max(ak.num(WWdr,axis = 1)) for test\n",
    "match_dR = 0.8\n",
    "HWW_match = WWdr <= match_dR #FatJetIdx in each event, which is real HWW jet\n",
    "\n",
    "HWWJets_tagger_score_lvqq = ak.pad_none(tagger_scores[HWW_match], 1, axis=1)[:, 0]\n",
    "\n",
    "HWWJets_tagger_score_lvqq = HWWJets_tagger_score_lvqq[Hlvqq_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(HWWJets_tagger_score_lvqq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Hlvqq_len = len(HWWJets_tagger_score_lvqq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to calculate Lund Plane weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '')\n",
    "sys.path.append(\"/home/pku/zhaoyz/Higgs/LundReweighting\")\n",
    "from utils.LundReweighter import *\n",
    "from utils.Utils import *\n",
    "\"\"\" An example how to use the Lund Plane reweighting  code \"\"\"\n",
    "\n",
    "######################## Setup \n",
    "\n",
    "#Input file \n",
    "fname = \"/home/pku/zhaoyz/Higgs/LundReweighting/data/example_signal.h5\"\n",
    "#File containing data/MC Lund Plane ratio\n",
    "f_ratio_name = '/home/pku/zhaoyz/Higgs/LundReweighting/data/ratio_2018.root'\n",
    "\n",
    "f_sig = h5py.File(fname, \"r\")\n",
    "f_ratio = ROOT.TFile.Open(f_ratio_name)\n",
    "\n",
    "#Class to help read input dataset, \"Dataset\" class defined in Utils.py\n",
    "# d = Dataset(f_sig, dtype = 1)\n",
    "# d.compute_obs() #there may be some dedicated variables inside the .h5 file\n",
    "\n",
    "#The cut we will compute a SF for 'tau21 < 0.34'\n",
    "tag_obs = 'tau21'\n",
    "score_thresh = 0.975\n",
    "\n",
    "\n",
    "#nominal data/MC Lund plane ratio (3d histogram)\n",
    "h_ratio = f_ratio.Get(\"ratio_nom\")\n",
    "#systematic variations\n",
    "h_ratio_sys_up = f_ratio.Get(\"ratio_sys_tot_up\")\n",
    "h_ratio_sys_down = f_ratio.Get(\"ratio_sys_tot_down\")\n",
    "#MC ratio of b to light quarks\n",
    "b_light_ratio = f_ratio.Get(\"h_bl_ratio\")\n",
    "\n",
    "\n",
    "#directory of pt extrapolation fits\n",
    "f_ratio.cd('pt_extrap')\n",
    "rdir = ROOT.gDirectory #get the present working directory and give it to rdir\n",
    "\n",
    "#Main class for reweighting utilities\n",
    "LP_rw = LundReweighter(pt_extrap_dir = rdir)\n",
    "\n",
    "max_evts = Hlvqq_len\n",
    "\n",
    "# score = getattr(d, tag_obs)[:max_evts]\n",
    "score_cut = ((HWWJets_tagger_score_lvqq >= 0.8) & (HWWJets_tagger_score_lvqq <= 0.975))\n",
    "# score_cut = (HWWJets_tagger_score > 0.975)\n",
    "score_cut = score_cut[:max_evts]\n",
    "\n",
    "\n",
    "#Number of toys for statistical and pt extrapolation uncertainties\n",
    "nToys = 100\n",
    "#Noise vectors used to to generate the toys\n",
    "#NOTE the same vector has to be used for the whole sample/signal file for the toys to be consistent \n",
    "rand_noise = np.random.normal(size = (nToys, h_ratio.GetNbinsX(), h_ratio.GetNbinsY(), h_ratio.GetNbinsZ()))\n",
    "pt_rand_noise = np.random.normal(size = (nToys, h_ratio.GetNbinsY(), h_ratio.GetNbinsZ(), 3))\n",
    "\n",
    "\n",
    "################### Compute reweighting factors\n",
    "\n",
    "#PF candidates in the AK8 jet\n",
    "# pf_cands = d.get_masked(\"jet1_PFCands\").astype(np.float64)[:max_evts]\n",
    "pf_cands = pf_cands_pxpypzE_lvqq[:max_evts]\n",
    "#Generator level quarks from hard process\n",
    "\n",
    "# gen_parts = d.get_masked('gen_info')[:max_evts]\n",
    "gen_parts_eta_phi = gen_parts_eta_phi_Hlvqq_2q[:max_evts]\n",
    "# gen_parts_pdg_ids = gen_parts[:,:,3]\n",
    "\n",
    "B_PDG_ID = 5\n",
    "\n",
    "# ak8_jets = d.get_masked('jet_kinematics')[:max_evts][:,2:6].astype(np.float64)\n",
    "ak8_jets = higgs_jet_4vec_Hlvqq[:max_evts]\n",
    "\n",
    "#Nominal event weights of the MC, assume every event is weight '1' for this example\n",
    "weights_nom = np.ones(max_evts)\n",
    "\n",
    "LP_weights = []\n",
    "LP_weights_sys_up = []\n",
    "LP_weights_sys_down = []\n",
    "stat_smeared_weights = []\n",
    "pt_smeared_weights = []\n",
    "b_weights_up = []\n",
    "b_weights_down = []\n",
    "bad_matches = []\n",
    "\n",
    "\n",
    "for i,cands in enumerate(pf_cands):\n",
    "    # if i == 4: break\n",
    "    # print(\"now processing:\",i)\n",
    "    #Get the subjets, splittings and checking matching based on PF candidates in the jet and gen-level quarks\n",
    "    subjets, splittings, bad_match, deltaRs = LP_rw.get_splittings_and_matching(cands, gen_parts_eta_phi[i], ak8_jets[i])\n",
    "    # print(bad_match)\n",
    "    # print(deltaRs)\n",
    "    #Gets the nominal LP reweighting factor for this event and statistical + pt extrapolation toys\n",
    "    LP_weight, stat_smeared_weight, pt_smeared_weight = LP_rw.reweight_lund_plane(h_rw = h_ratio, subjets = subjets, splittings = splittings,\n",
    "            rand_noise = rand_noise, pt_rand_noise = pt_rand_noise, )\n",
    "    #Now get systematic variations\n",
    "    LP_weight_sys_up,_,_ = LP_rw.reweight_lund_plane(h_rw = h_ratio_sys_up, subjets = subjets, splittings = splittings)\n",
    "    LP_weight_sys_down,_,_ = LP_rw.reweight_lund_plane(h_rw = h_ratio_sys_down, subjets = subjets, splittings = splittings)\n",
    "\n",
    "    LP_weights.append(LP_weight)\n",
    "    stat_smeared_weights.append(stat_smeared_weight)\n",
    "    pt_smeared_weights.append(pt_smeared_weight)\n",
    "\n",
    "    LP_weights_sys_up.append(LP_weight_sys_up)\n",
    "    LP_weights_sys_down.append(LP_weight_sys_down)\n",
    "    bad_matches.append(bad_match)\n",
    "\n",
    "\n",
    "\n",
    "############### Normalize weights to preserve normalization of the MC sample\n",
    "\n",
    "#The nominal Lund Plane correction event weights\n",
    "LP_weights = LP_rw.normalize_weights(LP_weights) * weights_nom \n",
    "\n",
    "#Toy variations for stat and pt uncertainties\n",
    "stat_smeared_weights = LP_rw.normalize_weights(stat_smeared_weights) * weights_nom.reshape(max_evts, 1)\n",
    "pt_smeared_weights = LP_rw.normalize_weights(pt_smeared_weights) * weights_nom.reshape(max_evts,1)\n",
    "\n",
    "#Systematic up/down variations\n",
    "LP_weights_sys_up = LP_rw.normalize_weights(LP_weights_sys_up) * weights_nom\n",
    "LP_weights_sys_down = LP_rw.normalize_weights(LP_weights_sys_down) * weights_nom\n",
    "\n",
    "############### Compute efficiences and uncertainties\n",
    "\n",
    "\n",
    "#Efficiency of the cut in nominal MC\n",
    "eff_nom = np.average(score_cut, weights = weights_nom) #TODO\n",
    "\n",
    "#Efficiency of the cut after the Lund Plane reweighting\n",
    "eff_rw = np.average(score_cut, weights = LP_weights)\n",
    "\n",
    "#Nominal 'scale factor'\n",
    "SF = eff_rw / eff_nom\n",
    "\n",
    "print(\"Nominal efficiency %.3f, Corrected efficiency %.3f, SF (corrected / nom) %.3f\" % (eff_nom, eff_rw, SF))\n",
    "\n",
    "#NOTE, better to use corrected efficiency computed separately for each sample rather than a single 'SF'\n",
    "\n",
    "\n",
    "#Compute efficiency for each of the stat/pt toys\n",
    "eff_toys = []\n",
    "pt_eff_toys = []\n",
    "for i in range(nToys):\n",
    "    eff = np.average(score_cut, weights = stat_smeared_weights[:,i])\n",
    "    eff_toys.append(eff)\n",
    "\n",
    "    eff1 = np.average(score_cut, weights = pt_smeared_weights[:,i])\n",
    "    pt_eff_toys.append(eff1)\n",
    "\n",
    "#Compute stat and pt uncertainty based on variation in the toys\n",
    "toys_mean = np.mean(eff_toys)\n",
    "toys_std = np.std(eff_toys)\n",
    "pt_toys_mean = np.mean(pt_eff_toys)\n",
    "pt_toys_std = np.std(pt_eff_toys)\n",
    "\n",
    "eff_stat_unc = (abs(toys_mean - eff_rw)  + toys_std) \n",
    "eff_pt_unc = (abs(pt_toys_mean - eff_rw) + pt_toys_std)\n",
    "\n",
    "print(\"Stat variation toys eff. avg %.3f, std dev %.3f\" % (toys_mean, toys_std))\n",
    "print(\"Pt variation toys eff. avg %.3f, std dev %.3f\" % (pt_toys_mean, pt_toys_std))\n",
    "\n",
    "\n",
    "#Compute difference in efficiency due to weight variations as uncertainty\n",
    "def get_uncs(score_cut, weights_up, weights_down, eff_baseline):\n",
    "    eff_up =  np.average(score_cut, weights = weights_up)\n",
    "    eff_down =  np.average(score_cut, weights = weights_down)\n",
    "\n",
    "    unc_up = eff_up - eff_baseline\n",
    "    unc_down = eff_down - eff_baseline \n",
    "    return unc_up, unc_down\n",
    "\n",
    "\n",
    "#Compute efficiency of systematic variations\n",
    "sys_unc_up, sys_unc_down = get_uncs(score_cut, LP_weights_sys_up, LP_weights_sys_down, eff_rw)\n",
    "# b_unc_up, b_unc_down = get_uncs(score_cut, b_weights_up, b_weights_down, eff_rw)\n",
    "\n",
    "\n",
    "#matching uncertainty, taken as a fractional uncertainty on efficiency\n",
    "bad_match_frac = np.mean(bad_matches)\n",
    "bad_match_unc = bad_match_frac * eff_rw\n",
    "\n",
    "\n",
    "############ Results\n",
    "print(\"\\n\\nCalibrated efficiency  is %.3f +/- %.3f  (stat) +/- %.3f (pt) +/- %.3f/%.3f (sys)+/- %.3f (matching)  \\n\\n\"  % \n",
    "        (eff_rw, eff_stat_unc, eff_pt_unc, sys_unc_up, sys_unc_down, bad_match_unc))\n",
    "\n",
    "#next compute the uncertainty about SFs\n",
    "\n",
    "#Efficiency of the cut in nominal MC\n",
    "eff_nom = np.average(score_cut, weights = weights_nom) #TODO\n",
    "\n",
    "#Efficiency of the cut after the Lund Plane reweighting\n",
    "eff_rw = np.average(score_cut, weights = LP_weights)\n",
    "\n",
    "#Nominal 'scale factor'\n",
    "print(\"Now perform SFs information\")\n",
    "SF = eff_rw / eff_nom\n",
    "\n",
    "print(\"SF (corrected / nom) %.3f\" % (SF))\n",
    "\n",
    "#propagate statistical and pt extrapolation uncertainties to SF\n",
    "SF_stat_unc = (abs(toys_mean - eff_rw)  + toys_std) /eff_nom\n",
    "SF_pt_unc = (abs(pt_toys_mean - eff_rw) + pt_toys_std) /eff_nom\n",
    "\n",
    "#propagate systemetic uncertainty to SF\n",
    "eff_sys_up =  np.average(score_cut, weights = LP_weights_sys_up)\n",
    "eff_sys_down =  np.average(score_cut, weights = LP_weights_sys_down)\n",
    "\n",
    "sys_unc_up = abs(eff_rw - eff_sys_up)\n",
    "sys_unc_down = abs(eff_rw - eff_sys_down)\n",
    "\n",
    "SF_sys_unc_up = sys_unc_up/eff_nom\n",
    "SF_sys_unc_down = sys_unc_down/eff_nom\n",
    "\n",
    "#calculate bad matching uncertainty directly\n",
    "SF_match_unc = bad_match_frac * SF\n",
    "\n",
    "print(\"\\n\\nSF is %.3f +/-%.3f(stat) +/-%.3f(pt) +%.3f/-%.3f(sys) +/-%.3f(match) \\n\\n\"  % (SF, SF_stat_unc, SF_pt_unc, sys_unc_up, sys_unc_down, SF_match_unc))\n",
    "f_ratio.Close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the tagger distribution about Hlvqq jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from cycler import cycler\n",
    "max_evts = Hlvqq_len\n",
    "#implement CMS plot style functions\n",
    "use_helvet = False ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax=plt.gca()\n",
    "plt.grid()\n",
    "hep.cms.label(data=False, year=\"2018\", ax=ax, fontname='sans-serif')\n",
    "%matplotlib inline\n",
    "#step1: plot \n",
    "\n",
    "# plt.hist(eventsEventsID3Prongs4Prongs['HqqqqVsQcdTop'], bins=20, range=(0,1), histtype='step', label='before reweighting',density=True);\n",
    "# plt.hist(eventsEventsID3Prongs4Prongs['HqqqqVsQcdTop'], bins=20, range=(0,1), histtype='step', label='after reweighting', weights=eventsEventsID3Prongs4Prongs[\"LP_weight\"],density=True);\n",
    "nbins, x_min, x_max = 20, 0, 1.0\n",
    "hist_before = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "hist_before.fill(HWWJets_tagger_score_lvqq[:max_evts])\n",
    "hist_before_value = hist_before.view().value\n",
    "hist_before_err = np.sqrt(hist_before.view().variance)\n",
    "\n",
    "hist_after = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "hist_after.fill(HWWJets_tagger_score_lvqq[:max_evts],weight=LP_weights[:max_evts])\n",
    "hist_after_value = hist_after.view().value\n",
    "hist_after_err = np.sqrt(hist_after.view().variance)\n",
    "bins = hist_before.axes[0].edges\n",
    "\n",
    "\n",
    "hep.histplot(hist_before_value,    bins=bins, yerr=hist_before_err, label= 'before Lund Plane reweighting', lw = 2,edges = False, histtype=\"step\")\n",
    "hep.histplot(hist_after_value,     bins=bins, yerr=hist_after_err,  label= 'after Lund Plane reweighting', lw = 2,edges = False, histtype=\"step\")\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',frameon=False,fontsize=20)\n",
    "y_min,y_max = plt.gca().get_ylim()\n",
    "plt.text(0.08, 0.83*y_max, \"ggF,only for Hlvqq jet\", fontsize=20)\n",
    "# plt.xlabel(r'$H_{qqqq} / (H_{qqqq} + QCD + Top)$')\n",
    "plt.xlabel(r'HWWvs(all background) tagger score', fontsize=20, ha='right', x=1)\n",
    "plt.ylabel('Events(No xs-weighted)',fontsize=20, ha='right', y=1)\n",
    "plt.savefig(f\"TaggerDistribution_2018_ggF_Hlvqq_all.pdf\", bbox_inches='tight')\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Hlvqq and H3q4q jets together to get final SFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# need to concat all the information together and get the whole SFs\n",
    "# but not get LP weight separately and concat LP weight together\n",
    "gen_parts_eta_phi_H3q4qlvqq = gen_parts_eta_phi_H3q4q_4q.tolist() + gen_parts_eta_phi_Hlvqq_2q.tolist()\n",
    "pf_cands_pxpypzE_H3q4qlvqq = np.concatenate([pf_cands_pxpypzE_4q,pf_cands_pxpypzE_lvqq],axis = 0)\n",
    "higgs_jet_4vec_H3q4qlvqq = np.concatenate([higgs_jet_4vec_H3q4q,higgs_jet_4vec_Hlvqq],axis = 0)\n",
    "HWWJets_tagger_score_H3q4qlvqq = np.concatenate([HWWJets_tagger_score_3q4q,HWWJets_tagger_score_lvqq],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#not all these 3 input array are with Hlvqq_cut\n",
    "print(len(gen_parts_eta_phi_H3q4qlvqq))\n",
    "print(len(pf_cands_pxpypzE_H3q4qlvqq))\n",
    "print(len(higgs_jet_4vec_H3q4qlvqq))\n",
    "print(len(HWWJets_tagger_score_H3q4qlvqq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "H3q4qlvqq_len = len(gen_parts_eta_phi_H3q4qlvqq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then calculate the SFs and Lund Plane weight in the entire HWW jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '')\n",
    "sys.path.append(\"/home/pku/zhaoyz/Higgs/LundReweighting\")\n",
    "from utils.LundReweighter import *\n",
    "from utils.Utils import *\n",
    "\"\"\" An example how to use the Lund Plane reweighting  code \"\"\"\n",
    "\n",
    "######################## Setup \n",
    "\n",
    "#Input file \n",
    "fname = \"/home/pku/zhaoyz/Higgs/LundReweighting/data/example_signal.h5\"\n",
    "#File containing data/MC Lund Plane ratio\n",
    "f_ratio_name = '/home/pku/zhaoyz/Higgs/LundReweighting/data/ratio_2018.root'\n",
    "\n",
    "f_sig = h5py.File(fname, \"r\")\n",
    "f_ratio = ROOT.TFile.Open(f_ratio_name)\n",
    "\n",
    "#Class to help read input dataset, \"Dataset\" class defined in Utils.py\n",
    "# d = Dataset(f_sig, dtype = 1)\n",
    "# d.compute_obs() #there may be some dedicated variables inside the .h5 file\n",
    "\n",
    "#The cut we will compute a SF for 'tau21 < 0.34'\n",
    "tag_obs = 'tau21'\n",
    "score_thresh = 0.975\n",
    "\n",
    "\n",
    "#nominal data/MC Lund plane ratio (3d histogram)\n",
    "h_ratio = f_ratio.Get(\"ratio_nom\")\n",
    "#systematic variations\n",
    "h_ratio_sys_up = f_ratio.Get(\"ratio_sys_tot_up\")\n",
    "h_ratio_sys_down = f_ratio.Get(\"ratio_sys_tot_down\")\n",
    "#MC ratio of b to light quarks\n",
    "b_light_ratio = f_ratio.Get(\"h_bl_ratio\")\n",
    "\n",
    "\n",
    "#directory of pt extrapolation fits\n",
    "f_ratio.cd('pt_extrap')\n",
    "rdir = ROOT.gDirectory #get the present working directory and give it to rdir\n",
    "\n",
    "#Main class for reweighting utilities\n",
    "LP_rw = LundReweighter(pt_extrap_dir = rdir)\n",
    "\n",
    "max_evts = H3q4qlvqq_len\n",
    "\n",
    "# score = getattr(d, tag_obs)[:max_evts]\n",
    "# score_cut = ((HWWJets_tagger_score_H3q4qlvqq >= 0.8) & (HWWJets_tagger_score_H3q4qlvqq <= 0.975))\n",
    "score_cut = (HWWJets_tagger_score_H3q4qlvqq > 0.975)\n",
    "score_cut = score_cut[:max_evts]\n",
    "\n",
    "\n",
    "#Number of toys for statistical and pt extrapolation uncertainties\n",
    "nToys = 100\n",
    "#Noise vectors used to to generate the toys\n",
    "#NOTE the same vector has to be used for the whole sample/signal file for the toys to be consistent \n",
    "rand_noise = np.random.normal(size = (nToys, h_ratio.GetNbinsX(), h_ratio.GetNbinsY(), h_ratio.GetNbinsZ()))\n",
    "pt_rand_noise = np.random.normal(size = (nToys, h_ratio.GetNbinsY(), h_ratio.GetNbinsZ(), 3))\n",
    "\n",
    "\n",
    "################### Compute reweighting factors\n",
    "\n",
    "#PF candidates in the AK8 jet\n",
    "# pf_cands = d.get_masked(\"jet1_PFCands\").astype(np.float64)[:max_evts]\n",
    "pf_cands = pf_cands_pxpypzE_H3q4qlvqq[:max_evts]\n",
    "#Generator level quarks from hard process\n",
    "\n",
    "# gen_parts = d.get_masked('gen_info')[:max_evts]\n",
    "gen_parts_eta_phi = gen_parts_eta_phi_H3q4qlvqq[:max_evts]\n",
    "# gen_parts_pdg_ids = gen_parts[:,:,3]\n",
    "\n",
    "B_PDG_ID = 5\n",
    "\n",
    "# ak8_jets = d.get_masked('jet_kinematics')[:max_evts][:,2:6].astype(np.float64)\n",
    "ak8_jets = higgs_jet_4vec_H3q4qlvqq[:max_evts]\n",
    "\n",
    "#Nominal event weights of the MC, assume every event is weight '1' for this example\n",
    "weights_nom = np.ones(max_evts)\n",
    "\n",
    "LP_weights = []\n",
    "LP_weights_sys_up = []\n",
    "LP_weights_sys_down = []\n",
    "stat_smeared_weights = []\n",
    "pt_smeared_weights = []\n",
    "b_weights_up = []\n",
    "b_weights_down = []\n",
    "bad_matches = []\n",
    "\n",
    "\n",
    "for i,cands in enumerate(pf_cands):\n",
    "    # if i == 4: break\n",
    "    # print(\"now processing:\",i)\n",
    "    #Get the subjets, splittings and checking matching based on PF candidates in the jet and gen-level quarks\n",
    "    subjets, splittings, bad_match, deltaRs = LP_rw.get_splittings_and_matching(cands, np.array(gen_parts_eta_phi[i]), ak8_jets[i])\n",
    "    # print(bad_match)\n",
    "    # print(deltaRs)\n",
    "    #Gets the nominal LP reweighting factor for this event and statistical + pt extrapolation toys\n",
    "    LP_weight, stat_smeared_weight, pt_smeared_weight = LP_rw.reweight_lund_plane(h_rw = h_ratio, subjets = subjets, splittings = splittings,\n",
    "            rand_noise = rand_noise, pt_rand_noise = pt_rand_noise, )\n",
    "    #Now get systematic variations\n",
    "    LP_weight_sys_up,_,_ = LP_rw.reweight_lund_plane(h_rw = h_ratio_sys_up, subjets = subjets, splittings = splittings)\n",
    "    LP_weight_sys_down,_,_ = LP_rw.reweight_lund_plane(h_rw = h_ratio_sys_down, subjets = subjets, splittings = splittings)\n",
    "\n",
    "    LP_weights.append(LP_weight)\n",
    "    stat_smeared_weights.append(stat_smeared_weight)\n",
    "    pt_smeared_weights.append(pt_smeared_weight)\n",
    "\n",
    "    LP_weights_sys_up.append(LP_weight_sys_up)\n",
    "    LP_weights_sys_down.append(LP_weight_sys_down)\n",
    "    bad_matches.append(bad_match)\n",
    "\n",
    "\n",
    "\n",
    "############### Normalize weights to preserve normalization of the MC sample\n",
    "\n",
    "#The nominal Lund Plane correction event weights\n",
    "LP_weights = LP_rw.normalize_weights(LP_weights) * weights_nom \n",
    "\n",
    "#Toy variations for stat and pt uncertainties\n",
    "stat_smeared_weights = LP_rw.normalize_weights(stat_smeared_weights) * weights_nom.reshape(max_evts, 1)\n",
    "pt_smeared_weights = LP_rw.normalize_weights(pt_smeared_weights) * weights_nom.reshape(max_evts,1)\n",
    "\n",
    "#Systematic up/down variations\n",
    "LP_weights_sys_up = LP_rw.normalize_weights(LP_weights_sys_up) * weights_nom\n",
    "LP_weights_sys_down = LP_rw.normalize_weights(LP_weights_sys_down) * weights_nom\n",
    "\n",
    "############### Compute efficiences and uncertainties\n",
    "\n",
    "\n",
    "#Efficiency of the cut in nominal MC\n",
    "eff_nom = np.average(score_cut, weights = weights_nom) #TODO\n",
    "\n",
    "#Efficiency of the cut after the Lund Plane reweighting\n",
    "eff_rw = np.average(score_cut, weights = LP_weights)\n",
    "\n",
    "#Nominal 'scale factor'\n",
    "SF = eff_rw / eff_nom\n",
    "\n",
    "print(\"Nominal efficiency %.3f, Corrected efficiency %.3f, SF (corrected / nom) %.3f\" % (eff_nom, eff_rw, SF))\n",
    "\n",
    "#NOTE, better to use corrected efficiency computed separately for each sample rather than a single 'SF'\n",
    "\n",
    "\n",
    "#Compute efficiency for each of the stat/pt toys\n",
    "eff_toys = []\n",
    "pt_eff_toys = []\n",
    "for i in range(nToys):\n",
    "    eff = np.average(score_cut, weights = stat_smeared_weights[:,i])\n",
    "    eff_toys.append(eff)\n",
    "\n",
    "    eff1 = np.average(score_cut, weights = pt_smeared_weights[:,i])\n",
    "    pt_eff_toys.append(eff1)\n",
    "\n",
    "#Compute stat and pt uncertainty based on variation in the toys\n",
    "toys_mean = np.mean(eff_toys)\n",
    "toys_std = np.std(eff_toys)\n",
    "pt_toys_mean = np.mean(pt_eff_toys)\n",
    "pt_toys_std = np.std(pt_eff_toys)\n",
    "\n",
    "eff_stat_unc = (abs(toys_mean - eff_rw)  + toys_std) \n",
    "eff_pt_unc = (abs(pt_toys_mean - eff_rw) + pt_toys_std)\n",
    "\n",
    "print(\"Stat variation toys eff. avg %.3f, std dev %.3f\" % (toys_mean, toys_std))\n",
    "print(\"Pt variation toys eff. avg %.3f, std dev %.3f\" % (pt_toys_mean, pt_toys_std))\n",
    "\n",
    "\n",
    "#Compute difference in efficiency due to weight variations as uncertainty\n",
    "def get_uncs(score_cut, weights_up, weights_down, eff_baseline):\n",
    "    eff_up =  np.average(score_cut, weights = weights_up)\n",
    "    eff_down =  np.average(score_cut, weights = weights_down)\n",
    "\n",
    "    unc_up = eff_up - eff_baseline\n",
    "    unc_down = eff_down - eff_baseline \n",
    "    return unc_up, unc_down\n",
    "\n",
    "\n",
    "#Compute efficiency of systematic variations\n",
    "sys_unc_up, sys_unc_down = get_uncs(score_cut, LP_weights_sys_up, LP_weights_sys_down, eff_rw)\n",
    "# b_unc_up, b_unc_down = get_uncs(score_cut, b_weights_up, b_weights_down, eff_rw)\n",
    "\n",
    "\n",
    "#matching uncertainty, taken as a fractional uncertainty on efficiency\n",
    "bad_match_frac = np.mean(bad_matches)\n",
    "bad_match_unc = bad_match_frac * eff_rw\n",
    "\n",
    "\n",
    "############ Results\n",
    "print(\"\\n\\nCalibrated efficiency  is %.3f +/- %.3f  (stat) +/- %.3f (pt) +/- %.3f/%.3f (sys)+/- %.3f (matching)  \\n\\n\"  % \n",
    "        (eff_rw, eff_stat_unc, eff_pt_unc, sys_unc_up, sys_unc_down, bad_match_unc))\n",
    "\n",
    "#next compute the uncertainty about SFs\n",
    "\n",
    "#Efficiency of the cut in nominal MC\n",
    "eff_nom = np.average(score_cut, weights = weights_nom) #TODO\n",
    "\n",
    "#Efficiency of the cut after the Lund Plane reweighting\n",
    "eff_rw = np.average(score_cut, weights = LP_weights)\n",
    "\n",
    "#Nominal 'scale factor'\n",
    "print(\"Now perform SFs information\")\n",
    "SF = eff_rw / eff_nom\n",
    "\n",
    "print(\"SF (corrected / nom) %.3f\" % (SF))\n",
    "\n",
    "#propagate statistical and pt extrapolation uncertainties to SF\n",
    "SF_stat_unc = (abs(toys_mean - eff_rw)  + toys_std) /eff_nom\n",
    "SF_pt_unc = (abs(pt_toys_mean - eff_rw) + pt_toys_std) /eff_nom\n",
    "\n",
    "#propagate systemetic uncertainty to SF\n",
    "eff_sys_up =  np.average(score_cut, weights = LP_weights_sys_up)\n",
    "eff_sys_down =  np.average(score_cut, weights = LP_weights_sys_down)\n",
    "\n",
    "sys_unc_up = abs(eff_rw - eff_sys_up)\n",
    "sys_unc_down = abs(eff_rw - eff_sys_down)\n",
    "\n",
    "SF_sys_unc_up = sys_unc_up/eff_nom\n",
    "SF_sys_unc_down = sys_unc_down/eff_nom\n",
    "\n",
    "#calculate bad matching uncertainty directly\n",
    "SF_match_unc = bad_match_frac * SF\n",
    "\n",
    "print(\"\\n\\nSF is %.3f +/-%.3f(stat) +/-%.3f(pt) +%.3f/-%.3f(sys) +/-%.3f(match) \\n\\n\"  % (SF, SF_stat_unc, SF_pt_unc, sys_unc_up, sys_unc_down, SF_match_unc))\n",
    "print(\"total unc. = \",np.sqrt(SF_stat_unc **2 + SF_pt_unc**2 + sys_unc_up**2 + SF_match_unc**2 ))\n",
    "f_ratio.Close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the entire HWW jets tagger distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from cycler import cycler\n",
    "max_evts = H3q4qlvqq_len\n",
    "#implement CMS plot style functions\n",
    "use_helvet = False ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax=plt.gca()\n",
    "plt.grid()\n",
    "hep.cms.label(data=False, year=\"2018\", ax=ax, fontname='sans-serif')\n",
    "%matplotlib inline\n",
    "#step1: plot \n",
    "\n",
    "# plt.hist(eventsEventsID3Prongs4Prongs['HqqqqVsQcdTop'], bins=20, range=(0,1), histtype='step', label='before reweighting',density=True);\n",
    "# plt.hist(eventsEventsID3Prongs4Prongs['HqqqqVsQcdTop'], bins=20, range=(0,1), histtype='step', label='after reweighting', weights=eventsEventsID3Prongs4Prongs[\"LP_weight\"],density=True);\n",
    "nbins, x_min, x_max = 20, 0, 1.0\n",
    "hist_before = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "hist_before.fill(HWWJets_tagger_score_H3q4qlvqq[:max_evts])\n",
    "hist_before_value = hist_before.view().value\n",
    "hist_before_err = np.sqrt(hist_before.view().variance)\n",
    "\n",
    "hist_after = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "hist_after.fill(HWWJets_tagger_score_H3q4qlvqq[:max_evts],weight=LP_weights[:max_evts])\n",
    "hist_after_value = hist_after.view().value\n",
    "hist_after_err = np.sqrt(hist_after.view().variance)\n",
    "bins = hist_before.axes[0].edges\n",
    "\n",
    "\n",
    "hep.histplot(hist_before_value,    bins=bins, yerr=hist_before_err, label= 'before Lund Plane reweighting', lw = 2,edges = False, histtype=\"step\")\n",
    "hep.histplot(hist_after_value,     bins=bins, yerr=hist_after_err,  label= 'after Lund Plane reweighting', lw = 2,edges = False, histtype=\"step\")\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',frameon=False,fontsize=20)\n",
    "y_min,y_max = plt.gca().get_ylim()\n",
    "plt.text(0.08, 0.83*y_max, \"for H3q, H4q, Hlvqq jets in ggF\", fontsize=20)\n",
    "# plt.xlabel(r'$H_{qqqq} / (H_{qqqq} + QCD + Top)$')\n",
    "plt.xlabel(r'HWWvs(all background) tagger score', fontsize=20, ha='right', x=1)\n",
    "plt.ylabel('Events(No xs-weighted)',fontsize=20, ha='right', y=1)\n",
    "plt.savefig(f\"TaggerDistribution_2018_ggF_H3q4qlvqq_all.pdf\", bbox_inches='tight')\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot pie-chart to show the fraction of different jet types with signal samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_dphi(events):\n",
    "    pT_higgs   = events[\"PTj_V2_a\"]\n",
    "    eta_higgs  = events[\"Etaj_V2_a\"]\n",
    "    phi_higgs  = events[\"Phij_V2_a\"]\n",
    "    mass_higgs = events[\"Mj_V2_a\"]\n",
    "    pT_MET = events[\"MET_et\"]\n",
    "    eta_MET = events[\"Etaj_V2_a\"]\n",
    "    phi_MET = events[\"MET_phi\"]\n",
    "    mass_MET = ak.zeros_like(events[\"MET_phi\"])\n",
    "    vec_higgs = ak.zip({\n",
    "        \"pt\"   : pT_higgs   ,\n",
    "        \"eta\"  : eta_higgs  ,\n",
    "        \"phi\"  : phi_higgs  ,\n",
    "        \"mass\" : mass_higgs ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "    vec_MET = ak.zip({\n",
    "        \"pt\"   :   pT_MET   ,\n",
    "        \"eta\"  :  eta_MET  ,\n",
    "        \"phi\"  :  phi_MET  ,\n",
    "        \"mass\" : mass_MET ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "    delta_phi = np.subtract(vec_MET.phi, vec_higgs.phi)\n",
    "    delta_phi = np.where(delta_phi > np.pi, delta_phi - 2*np.pi, delta_phi)\n",
    "    delta_phi = np.where(delta_phi < -np.pi, delta_phi + 2*np.pi, delta_phi)\n",
    "    delta_phi = np.abs(delta_phi)\n",
    "    print(delta_phi)\n",
    "    events[\"DPhi\"] = delta_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from cycler import cycler\n",
    "\n",
    "events_signal = {\n",
    "        'ggF'         : \"/data/bond/zhaoyz/SlimmedTree/V5/Full-Run2/Signal/SlimmedTree_GluGlu.root\",\n",
    "        'VH'          : \"/data/bond/zhaoyz/SlimmedTree/V5/Full-Run2/Signal/SlimmedTree_VH.root\",   \n",
    "        'ttH'         : \"/data/bond/zhaoyz/SlimmedTree/V5/Full-Run2/Signal/SlimmedTree_ttH.root\",\n",
    "        'VBF'         : \"/data/bond/zhaoyz/SlimmedTree/V5/Full-Run2/Signal/SlimmedTree_VBF.root\",\n",
    "        'TotalSignal' : \"/data/bond/zhaoyz/SlimmedTree/V5/2018/Signal/SlimmedTree_Total.root\",\n",
    "}\n",
    "\n",
    "\n",
    "regions = [\"PS\",\"SR1a\",\"SR1b\",\"SR2a\",\"SR2b\",\"SR3a\",\"SR3b\"]\n",
    "for region_i in regions:\n",
    "    for file_name, file_path in events_signal.items():\n",
    "        use_helvet = False ## true: use helvetica for plots, make sure the system have the font installed\n",
    "        if use_helvet:\n",
    "            CMShelvet = hep.style.CMS\n",
    "            CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "            plt.style.use(CMShelvet)\n",
    "        else:\n",
    "            plt.style.use(hep.style.CMS)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        ax=plt.gca()\n",
    "        plt.grid()\n",
    "        hep.cms.label(data=False, year=\"Full-Run2\", ax=ax, fontname='sans-serif')\n",
    "        %matplotlib inline\n",
    "        events_pkutree = uproot.lazy({file_path:\"PKUTree\"})\n",
    "        get_dphi(events=events_pkutree)\n",
    "        CUT = {        \n",
    "            \"SR1a\" :  (events_pkutree[\"a_HWW_V2\"] > 0.975) & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] < 0.3),\n",
    "            \"SR1b\" :  (events_pkutree[\"a_HWW_V2\"] > 0.8)   & (events_pkutree[\"a_HWW_V2\"] <= 0.975) & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] < 0.3),\n",
    "            \"SR2a\" :  (events_pkutree[\"DPhi\"] < 0.8)       & (events_pkutree[\"a_HWW_V2\"] > 0.975)  & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] >= 0.3) & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] < 0.6),\n",
    "            \"SR2b\" :  (events_pkutree[\"a_HWW_V2\"] > 0.8)   & (events_pkutree[\"a_HWW_V2\"] <= 0.975) & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] >= 0.3) & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] < 0.6),\n",
    "            \"SR3a\" :  (events_pkutree[\"DPhi\"] < 0.8)       & (events_pkutree[\"a_HWW_V2\"] > 0.975)  & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] >= 0.6),\n",
    "            \"SR3b\" :  (events_pkutree[\"DPhi\"] < 0.8)       & (events_pkutree[\"a_HWW_V2\"] <= 0.975) & (events_pkutree[\"a_HWW_V2\"] > 0.8) & (events_pkutree[\"MET_et\"]/events_pkutree[\"PTj_V2_a\"] >= 0.6),\n",
    "        }\n",
    "        region = region_i #can choose SR1a,SR1b...\n",
    "        if region == \"PS\":\n",
    "            pass\n",
    "        else: events_pkutree = events_pkutree[CUT[region]]\n",
    "\n",
    "        num1_pkutree = np.sum(events_pkutree[events_pkutree[\"R4q_a\"] == 1][\"weight\"])\n",
    "        num2_pkutree = np.sum(events_pkutree[(events_pkutree[\"R3q_a\"] == 1) & (events_pkutree[\"R3q_taudecay_a\"] != 1)][\"weight\"])\n",
    "        num3_pkutree = np.sum(events_pkutree[(events_pkutree[\"Rlqq_a\"] == 1) | (events_pkutree[\"R3q_taudecay_a\"] == 1)][\"weight\"])\n",
    "        num4_pkutree = np.sum(events_pkutree[(events_pkutree[\"R4q_a\"] != 1) & (events_pkutree[\"R3q_a\"] != 1) & (events_pkutree[\"Rlqq_a\"] != 1) & (events_pkutree[\"R3q_taudecay_a\"] != 1)][\"weight\"])\n",
    "        labels = [r'$H^{4q}\\ matched$', r'$H^{3q}\\ matched$', r'$H^{lqq}\\ matched$', r'Others']\n",
    "        sizes = [num1_pkutree, num2_pkutree, num3_pkutree, num4_pkutree]\n",
    "        # color\n",
    "        colors = ['#ffff00', '#2ca02c', '#ff7f0e', '#800080']\n",
    "        # highlight some component(optional)\n",
    "        explode = (0., 0, 0, 0)\n",
    "        # plot the pie chat\n",
    "        plt.pie(sizes, labels=None, colors=colors, autopct='%1.1f%%', startangle=140, explode=explode)\n",
    "        plt.legend(labels, loc='upper right')\n",
    "        # set title\n",
    "        plt.title(r'$\\ \\ Signal' + \"\" + r'\\ jet_{a}\\ decomposition $',fontsize = 30)\n",
    "        # title_text = 'Pie Chart Example'\n",
    "        plt.text(-1,1.1, file_name + \", \" + region, fontsize=45)\n",
    "        plt.savefig(f\"Piechart_\"+file_name+region+\"_deco.pdf\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mUnable to start Kernel 'lpr (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HWWCali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
