{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: This is the Jupyter notebook to do the flowing things:\n",
    "\n",
    "1. Read slimmed PKU Tree files to plot JES/JER up/down distribution\n",
    "\n",
    "Enviroment needed for this script: HWW\n",
    "\n",
    "(I have exported the enviroment needed for this script, assume you have `Conda` installed in your terminal, then enter `../envs/` directory, and use  `conda env create -f HWW.yml` to create the enviroment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/pku/home/zhaoyz/anaconda3/envs/HWW/etc/cling/std.modulemap:257:29: warning: unknown attribute 'optional' [-Wignored-attributes]\n",
      "  module \"memory_resource\" [optional] {\n",
      "                            ^\n",
      "/data/pku/home/zhaoyz/anaconda3/envs/HWW/etc/cling/std.modulemap:447:27: warning: unknown attribute 'optional' [-Wignored-attributes]\n",
      "  module \"bits/chrono.h\" [optional] {\n",
      "                          ^\n",
      "/data/pku/home/zhaoyz/anaconda3/envs/HWW/etc/cling/std.modulemap:531:41: warning: unknown attribute 'optional' [-Wignored-attributes]\n",
      "  explicit module \"bits_ranges_base_h\" [optional] {\n",
      "                                        ^\n",
      "/data/pku/home/zhaoyz/anaconda3/envs/HWW/etc/cling/std.modulemap:538:32: warning: unknown attribute 'optional' [-Wignored-attributes]\n",
      "  module \"bits/ranges_util.h\" [optional] {\n",
      "                               ^\n",
      "/data/pku/home/zhaoyz/anaconda3/envs/HWW/etc/cling/std.modulemap:559:40: warning: unknown attribute 'optional' [-Wignored-attributes]\n",
      "  module \"bits/uses_allocator_args.h\" [optional] {\n",
      "                                       ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import awkward as ak\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from scipy import interpolate\n",
    "from cycler import cycler\n",
    "import uproot\n",
    "import ROOT\n",
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import hist as hist2\n",
    "import pyarrow\n",
    "import yaml\n",
    "from typing import Dict, List, Union\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea.nanoevents.methods import vector\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SlimmedTree files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the slimmedtree files using uproot\n",
    "\n",
    "#different year available here.\n",
    "# year = \"2016\"\n",
    "# year = \"2017\"\n",
    "year = \"2018\"\n",
    "# year = \"Full-Run2\"\n",
    "\n",
    "#if run on PKU cluster, use this:\n",
    "CustNanoData = {\n",
    "    'TotalSignal' : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_Total.root\"%(year),\n",
    "    'ggF'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_GluGlu.root\"%(year),\n",
    "    'VH'          : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_VH.root\"%(year),\n",
    "    'ttH'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_ttH.root\"%(year),\n",
    "    'VBF'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_VBF.root\"%(year),\n",
    "} \n",
    "\n",
    "files = {typefile : {} for typefile in CustNanoData}\n",
    "for typefile in CustNanoData:\n",
    "    files[typefile] = uproot.lazy({CustNanoData[typefile]: \"PKUTree\" })\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DPhi in the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dphi of: TotalSignal\n",
      "[0.486, 0.0852, 2.85, 0.551, 1.49, 0.535, ... 0.743, 0.839, 2.31, 2.44, 2.99, 0.506]\n",
      "Add dphi of: ggF\n",
      "[0.486, 0.0852, 2.85, 0.551, 1.49, 0.535, ... 3.09, 0.722, 3, 3.11, 3.07, 0.455]\n",
      "Add dphi of: VH\n",
      "[3.03, 1.91, 0.382, 2.28, 0.302, 3.03, ... 3.1, 0.141, 0.273, 0.498, 1.18, 2.73]\n",
      "Add dphi of: ttH\n",
      "[1.1, 0.131, 0.429, 1.78, 2.46, 0.0163, ... 0.743, 0.839, 2.31, 2.44, 2.99, 0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add dphi of: VBF\n",
      "[0.435, 1.79, 3.09, 0.797, 2.77, 0.561, ... 1.13, 0.332, 2.5, 2.82, 2.01, 2.45]\n"
     ]
    }
   ],
   "source": [
    "def get_dphi(events):\n",
    "    pT_higgs   = events[\"PTj_V2_a\"]\n",
    "    eta_higgs  = events[\"Etaj_V2_a\"]\n",
    "    phi_higgs  = events[\"Phij_V2_a\"]\n",
    "    mass_higgs = events[\"Mj_V2_a\"]\n",
    "    pT_MET = events[\"MET_et\"]\n",
    "    eta_MET = events[\"Etaj_V2_a\"]\n",
    "    phi_MET = events[\"MET_phi\"]\n",
    "    mass_MET = ak.zeros_like(events[\"MET_phi\"])\n",
    "    vec_higgs = ak.zip({\n",
    "        \"pt\"   : pT_higgs   ,\n",
    "        \"eta\"  : eta_higgs  ,\n",
    "        \"phi\"  : phi_higgs  ,\n",
    "        \"mass\" : mass_higgs ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "    vec_MET = ak.zip({\n",
    "        \"pt\"   :   pT_MET   ,\n",
    "        \"eta\"  :  eta_MET  ,\n",
    "        \"phi\"  :  phi_MET  ,\n",
    "        \"mass\" : mass_MET ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "    delta_phi = np.subtract(vec_MET.phi, vec_higgs.phi)\n",
    "    delta_phi = np.where(delta_phi > np.pi, delta_phi - 2*np.pi, delta_phi)\n",
    "    delta_phi = np.where(delta_phi < -np.pi, delta_phi + 2*np.pi, delta_phi)\n",
    "    delta_phi = np.abs(delta_phi)\n",
    "    print(delta_phi)\n",
    "    events[\"DPhi\"] = delta_phi\n",
    "\n",
    "for k in files:\n",
    "    print(\"Add dphi of:\",k)\n",
    "    get_dphi(events=files[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MET recovery mass(consider the JES/JER up/down content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add reco of: TotalSignal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add reco of: ggF\n",
      "Add reco of: VH\n",
      "Add reco of: ttH\n",
      "Add reco of: VBF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_reco(events,mass = \"Mj_V2_a\"):\n",
    "    pT_higgs   = events[\"PTj_V2_a\"]\n",
    "    eta_higgs  = events[\"Etaj_V2_a\"]\n",
    "    phi_higgs  = events[\"Phij_V2_a\"]\n",
    "    mass_higgs = events[mass]\n",
    "    pT_MET = events[\"MET_et\"]\n",
    "    eta_MET = events[\"Etaj_V2_a\"]\n",
    "    phi_MET = events[\"MET_phi\"]\n",
    "    mass_MET = ak.zeros_like(events[\"MET_phi\"])\n",
    "    vec_higgs = ak.zip({\n",
    "        \"pt\"   : pT_higgs   ,\n",
    "        \"eta\"  : eta_higgs  ,\n",
    "        \"phi\"  : phi_higgs  ,\n",
    "        \"mass\" : mass_higgs ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "\n",
    "    vec_MET = ak.zip({\n",
    "        \"pt\"   :   pT_MET   ,\n",
    "        \"eta\"  :  eta_MET  ,\n",
    "        \"phi\"  :  phi_MET  ,\n",
    "        \"mass\" : mass_MET ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "\n",
    "    vec_sum = vec_MET + vec_higgs\n",
    "    mH_reco = vec_sum.mass\n",
    "    mass_str = \"MH_Reco\" if mass == \"Mj_V2_a\" else mass\n",
    "    events[mass_str] = ak.where(( (events[\"DPhi\"] < 0.8) & (events[\"MET_et\"]/events[\"PTj_V2_a\"] > 0.1)), mH_reco, events[mass])\n",
    "\n",
    "for k in files:\n",
    "    print(\"Add reco of:\",k)\n",
    "    get_reco(events=files[k])\n",
    "    get_reco(events=files[k],mass = \"Mj_jesTotalUp_a\")\n",
    "    get_reco(events=files[k],mass = \"Mj_jesTotalDown_a\")\n",
    "    get_reco(events=files[k],mass = \"Mj_jerUp_a\")\n",
    "    get_reco(events=files[k],mass = \"Mj_jerDown_a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output all the variables for which we can make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MJJJ',\n",
       " 'PTj_3',\n",
       " 'Phij_V2_c',\n",
       " 'a_HWqqWtauhv1c',\n",
       " 't_a',\n",
       " 'a_HWqqWtauhv0c',\n",
       " 'a_HWqqWtaumv0c',\n",
       " 'R4q_a',\n",
       " 'tlqq_c',\n",
       " 'a_TopbWtauhv',\n",
       " 'PTj_V2_b',\n",
       " 'a_QCDb',\n",
       " 'Mj_V2_b',\n",
       " 'R4q_b',\n",
       " 'Mj_max',\n",
       " 'PTj_V2_a',\n",
       " 'MET_phi',\n",
       " 'a_TopbWtauev',\n",
       " 'Nj4_in',\n",
       " 'nb_t_deep_in',\n",
       " 'a_TopbWqq0c',\n",
       " 'a_TopbWev',\n",
       " 'c_HWW_V2',\n",
       " 'a_HWqqWq2c',\n",
       " 'MET_T1Smear_phi_XYcorr',\n",
       " 'a_HWW_V2',\n",
       " 'MET_T1Smear_pt_XYcorr',\n",
       " 'b_HWWvsQCD_V2',\n",
       " 'SF',\n",
       " 'a_TopbWqq1c',\n",
       " 'Mj_min',\n",
       " 'a_HWqqWqq2c',\n",
       " 'Phij_mid',\n",
       " 'Mj_corr_c',\n",
       " 'Mj_jesTotalUp_b',\n",
       " 'Mj_corr_b',\n",
       " 'Rlq_a',\n",
       " 'R3q_b',\n",
       " 'a_HWqqWmv0c',\n",
       " 'u_c',\n",
       " 'a_Hbb',\n",
       " 't_b',\n",
       " 'a_HWqqWev0c',\n",
       " 'PTj_min',\n",
       " 'PTj_max',\n",
       " 'R2q_c',\n",
       " 'Etaj_max',\n",
       " 'Rlq_b',\n",
       " 'Nj4_ex',\n",
       " 'nb_m_deep_ex',\n",
       " 'MET_et_NoXYCorr',\n",
       " 'a_HWqqWmv1c',\n",
       " 'Phij_min',\n",
       " 'Phij_3',\n",
       " 'tlqq_b',\n",
       " 'Mj_jerDown_c',\n",
       " 'nb_t_deep_ex',\n",
       " 'MET_phi_NoXYCorr',\n",
       " 'w_c',\n",
       " 'gKK_g_a',\n",
       " 'Phij_max',\n",
       " 'Mj_corr_2',\n",
       " 'Etaj_2',\n",
       " 'Mj_corr_a',\n",
       " 'Etaj_V2_c',\n",
       " 'w_a',\n",
       " 'a_HWqqWtauev1c',\n",
       " 'Mj',\n",
       " 'a_TopbWtaumv',\n",
       " 'R2q_b',\n",
       " 'Phij_V2_b',\n",
       " 'R3q_taudecay_c',\n",
       " 'Etaj_3',\n",
       " 'Phij_V2_a',\n",
       " 'a_Htauhtaum',\n",
       " 'ST',\n",
       " 'a_HWqqWq1c',\n",
       " 'u_a',\n",
       " 'PTj_V2_c',\n",
       " 'Mj_corr_3',\n",
       " 'a_HWqqWqq0c',\n",
       " 'z_b',\n",
       " 'a_Hss',\n",
       " 'Rlqq_a',\n",
       " 'a_Htauhtauh',\n",
       " 'tlqq_a',\n",
       " 'a_HWqqWtaumv1c',\n",
       " 'PTj',\n",
       " 'R3q_taudecay_a',\n",
       " 'Mj_jesTotalUp_c',\n",
       " 'a_Htauhtaue',\n",
       " 'Mj_V2_a',\n",
       " 'Mj_2',\n",
       " 'R3q_taudecay_b',\n",
       " 'a_TopbWq0c',\n",
       " 'R3q_c',\n",
       " 'z_c',\n",
       " 'R4q_c',\n",
       " 'Nj8',\n",
       " 'Etaj_mid',\n",
       " 'MJJ',\n",
       " 'Rlqq_c',\n",
       " 'Mj_V2_c',\n",
       " 'c_HWWvsQCD_V2',\n",
       " 'nb_l_deep_ex',\n",
       " 'Mj_jerDown_b',\n",
       " 'a_HWqqWtauev0c',\n",
       " 'R3q_a',\n",
       " 'weight',\n",
       " 'Mj_corr',\n",
       " 'a_HWWvsQCD_V2',\n",
       " 'gKK_g_b',\n",
       " 'Mj_jerUp_c',\n",
       " 'a_HWqqWev1c',\n",
       " 'Phij',\n",
       " 'a_HWqqWq0c',\n",
       " 'Etaj_V2_b',\n",
       " 'a_HWqqWqq1c',\n",
       " 'a_Hqq',\n",
       " 'Etaj',\n",
       " 'a_QCDcc',\n",
       " 'Mj_jesTotalDown_b',\n",
       " 'b_HWW_V2',\n",
       " 'Rlq_c',\n",
       " 'Mj_mid',\n",
       " 'Mj_jesTotalDown_c',\n",
       " 'Etaj_min',\n",
       " 'a_QCDbb',\n",
       " 'nb_l_deep_in',\n",
       " 'a_TopbWmv',\n",
       " 'PTj_mid',\n",
       " 'w_b',\n",
       " 'a_QCDothers',\n",
       " 'R2q_a',\n",
       " 'Rlqq_b',\n",
       " 'z_a',\n",
       " 't_c',\n",
       " 'Phij_2',\n",
       " 'Mj_3',\n",
       " 'a_QCDc',\n",
       " 'a_Hcc',\n",
       " 'u_b',\n",
       " 'nb_m_deep_in',\n",
       " 'gKK_g_c',\n",
       " 'MET_et',\n",
       " 'PTj_2',\n",
       " 'a_TopbWq1c',\n",
       " 'Etaj_V2_a',\n",
       " 'HT',\n",
       " 'Mj_jerUp_b',\n",
       " 'DPhi',\n",
       " 'MH_Reco',\n",
       " 'Mj_jesTotalUp_a',\n",
       " 'Mj_jesTotalDown_a',\n",
       " 'Mj_jerUp_a',\n",
       " 'Mj_jerDown_a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[\"VBF\"].fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot setting, error setting, histogram setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from cycler import cycler\n",
    "\n",
    "use_helvet = False ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)\n",
    "\n",
    "def flow(hist: bh.Histogram, overflow: bool=False, underflow: bool=False):\n",
    "    h, var = hist.view(flow=(overflow | underflow)).value, hist.view(flow=(overflow | underflow)).variance\n",
    "    if overflow: \n",
    "        # h, var also include underflow bins but in plots usually no underflow data\n",
    "        # And we've filled None with -999, so we shouldn't show underflow data (mostly from filled None)\n",
    "        # You have to access the overflow and underflow bins data like below:\n",
    "        h[-2] += h[-1]; var[-2] += var[-1]\n",
    "    if underflow:\n",
    "        h[1] += h[0]; var[1] += var[0]\n",
    "    if overflow or underflow:\n",
    "        h, var = h[1:-1], var[1:-1]\n",
    "    return h, var\n",
    "    # Return the updated histogram and variance\n",
    "\n",
    "def error_bar(h, var, type='data'):\n",
    "    from scipy.interpolate import CubicSpline\n",
    "    if type == 'data':\n",
    "        number = h\n",
    "    elif type == 'mc':  # h = k*N, var = k^2*N, std = k*sqrt(N)\n",
    "        number = h**2 / var\n",
    "    else:\n",
    "        raise ValueError(\"type should be 'data' or 'mc'! \")\n",
    "    center = range(11) # Number: 0-10\n",
    "    up = np.array([1.84, 3.30, 4.64, 5.92, 7.16, 8.38, 9.58, 10.77, 11.95, 13.11, 14.27]) - center\n",
    "    down = center - np.array([0, 0.17, 0.71, 1.37, 2.09, 2.84, 3.62, 4.42, 5.23, 6.06, 6.89])\n",
    "    #cs means to create a CubicSpline object\n",
    "    cs_up = CubicSpline(x=center, y=up)\n",
    "    cs_down = CubicSpline(x=center, y=down)\n",
    "    \n",
    "    Garwood = (number>0)&(number<10)\n",
    "    poison_error_bar = np.sqrt(number)\n",
    "    up_error_bar = np.copy(poison_error_bar)\n",
    "    down_error_bar = np.copy(poison_error_bar)\n",
    "    up_error_bar[Garwood] = cs_up(number[Garwood])\n",
    "    down_error_bar[Garwood] = cs_down(number[Garwood])\n",
    "    if type == 'mc':\n",
    "        up_error_bar *= var/h\n",
    "        down_error_bar *= var/h\n",
    "    up_error_bar [up_error_bar < 0 ] = 0\n",
    "    down_error_bar [down_error_bar < 0 ] = 0\n",
    "    return np.array([down_error_bar, up_error_bar])\n",
    "\n",
    "\n",
    "# function to find the optimal region with S/sqrt(B)\n",
    "# not used so far\n",
    "def optimalcut(shist, bhist):\n",
    "    n_bins = len(shist)\n",
    "    best_lower = None\n",
    "    best_upper = None\n",
    "    best_s_sqrt_b = 0\n",
    "\n",
    "    for lower in range(n_bins):\n",
    "        for upper in range(lower+1, n_bins+1):\n",
    "            s = np.sum(shist[lower:upper])\n",
    "            b = np.sum(bhist[lower:upper])\n",
    "            s_sqrt_b = s / np.sqrt(b + 1)\n",
    "\n",
    "            if s_sqrt_b > best_s_sqrt_b:\n",
    "                best_lower = lower\n",
    "                best_upper = upper\n",
    "                best_s_sqrt_b = s_sqrt_b\n",
    "\n",
    "    return best_lower, best_upper, best_s_sqrt_b\n",
    "\n",
    "def optimalcut_oneside(shist, bhist, epsilon = 0.01):\n",
    "    '''\n",
    "    Given the signal histogram and background histogram, \n",
    "    show the one-side cut for the variable to get best s/sqrt(b).\n",
    "    Args:\n",
    "        shist:signal histogram\n",
    "        bhist:background histogram\n",
    "        epsilon(float): epsilon to avoid numerical errs \n",
    "    '''\n",
    "    n_bins = len(shist)\n",
    "    best_cut = 0\n",
    "    best_s_sqrt_b = 0\n",
    "\n",
    "    for cut in range(n_bins):\n",
    "        s = np.sum(shist[cut:])\n",
    "        b = np.sum(bhist[cut:])\n",
    "        s_sqrt_b = s / np.sqrt(b + epsilon)\n",
    "        if s_sqrt_b > best_s_sqrt_b:\n",
    "            best_cut = cut\n",
    "            best_s_sqrt_b = s_sqrt_b\n",
    "        \n",
    "    return best_cut, best_s_sqrt_b\n",
    "\n",
    "def optimalcut_mid_combine(shist1, shist2, bhist, epsilon = 1):\n",
    "    '''\n",
    "    Given the signal histogram and background histogram, \n",
    "    show the one-side cut for the variable to get best s/sqrt(b).\n",
    "    Args:\n",
    "        shist:signal histogram\n",
    "        bhist:background histogram\n",
    "        epsilon(float): epsilon to avoid numerical errs \n",
    "    '''\n",
    "    n_bins = len(shist1)\n",
    "    best_cut = 0\n",
    "    best_combined_sig_two_side = 0\n",
    "\n",
    "    for cut in range(n_bins):\n",
    "        s_right_side = np.sum(shist2[cut:])\n",
    "        b_right_side = np.sum(bhist[cut:])\n",
    "        s_left_side = np.sum(shist1[:cut])\n",
    "        b_left_side = np.sum(bhist[:cut])\n",
    "        s_sqrt_b_right_side = s_right_side / np.sqrt(b_right_side + epsilon)\n",
    "        s_sqrt_b_left_side = s_left_side / np.sqrt(b_left_side + epsilon)\n",
    "        combined_sig_two_side = np.sqrt((s_sqrt_b_right_side)**2 + (s_sqrt_b_left_side)**2)\n",
    "        if combined_sig_two_side > best_combined_sig_two_side:\n",
    "            best_cut = cut\n",
    "            best_combined_sig_two_side = combined_sig_two_side\n",
    "        \n",
    "    return best_cut, best_combined_sig_two_side\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define main plots function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \".\"\n",
    "\n",
    "plot_dir = f\"{MAIN_DIR}/plots/JEC/27Feb24\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_JES_JER_variation(files, nbins=20, x_min=50, x_max=250, legend_location='upper left',suffix = \"\", region = \"PS\", plot_JES = True,year = \"2018\"):\n",
    "    # plt.rcParams['axes.prop_cycle'] = cycler(color=['red','blue','green','darkorange','cyan','black'])\n",
    "    plt.rcParams['axes.prop_cycle'] = cycler(color=[\"tab:blue\",\t\"tab:orange\",\t\"tab:green\",\t\"tab:red\",\t\"tab:purple\", \"tab:brown\", \"tab:pink\", \"k\",\"tab:olive\" ,\t\"tab:cyan\"])\n",
    "    # plt.figure(figsize=(14,10))\n",
    "    f = plt.figure(figsize=(14, 15))\n",
    "    gs = mpl.gridspec.GridSpec(2, 1, height_ratios=[3, 1], hspace=0.08)\n",
    "    ax = f.add_subplot(gs[0])\n",
    "    plt.grid()\n",
    "    LUMI = {\"2016\": 36.33, \"2017\": 41.48, \"2018\": 59.83,\"Full-Run2\":138}\n",
    "    hep.cms.label(loc = 1, data=True, year=year, ax=ax, lumi=LUMI[year], fontsize=18, llabel='Preliminary')\n",
    "    ax1 = f.add_subplot(gs[1])\n",
    "    ax1.grid()\n",
    "    def maskdict_sr(files_i, SR):\n",
    "        events = files_i\n",
    "        if   SR == \"SR1a\": maskdict_sr = ((events[\"MET_et\"]/events[\"PTj_V2_a\"] < 0.25 ) & (events[\"a_HWW_V2\"] >= 0.99))\n",
    "        elif SR == \"SR2a\": maskdict_sr = ((events[\"MET_et\"]/events[\"PTj_V2_a\"] >= 0.25) & (events[\"a_HWW_V2\"] >= 0.99) & (events[\"DPhi\"] < 0.8))\n",
    "        elif SR == \"SR1b\": maskdict_sr = ((events[\"MET_et\"]/events[\"PTj_V2_a\"] < 0.25 ) & (events[\"a_HWW_V2\"] >= 0.92) & (events[\"a_HWW_V2\"] < 0.99))\n",
    "        elif SR == \"SR2b\": maskdict_sr = ((events[\"MET_et\"]/events[\"PTj_V2_a\"] >= 0.25) & (events[\"a_HWW_V2\"] >= 0.92) & (events[\"a_HWW_V2\"] < 0.99) & (events[\"DPhi\"] < 0.8))\n",
    "        elif SR == \"PS\":   maskdict_sr = ((events[\"MET_et\"]/events[\"PTj_V2_a\"] >= 0))\n",
    "        else: print(\"invalid SR value\")\n",
    "        return maskdict_sr\n",
    "    \n",
    "    \n",
    "    if plot_JES:\n",
    "        hist_region = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        hist_region.fill(files[\"Mj_jesTotalUp_a\"][maskdict_sr(files,region)], weight = files[\"weight\"][maskdict_sr(files,region)])\n",
    "        hist_value_up = flow(hist_region)[0]\n",
    "        hist_var_up   = flow(hist_region)[1]\n",
    "        err_up = np.nan_to_num(error_bar(hist_value_up, hist_var_up, type = \"mc\"), nan = 0)\n",
    "        hep.histplot(hist_value_up, bins=hist_region.axes[0].edges, yerr=err_up, label=\"JES,total up\", histtype='step', stack=False, linewidth=2, ax=ax, color = \"red\")\n",
    "\n",
    "        hist_region = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        hist_region.fill(files[\"MH_Reco\"][maskdict_sr(files,region)], weight = files[\"weight\"][maskdict_sr(files,region)])\n",
    "        hist_value_nom = flow(hist_region)[0]\n",
    "        hist_var_nom   = flow(hist_region)[1]\n",
    "        err_nom = np.nan_to_num(error_bar(hist_value_nom, hist_var_nom, type = \"mc\"), nan = 0)\n",
    "        hep.histplot(hist_value_nom, bins=hist_region.axes[0].edges, yerr=err_nom, label=\"center\", histtype='step', stack=False, linewidth=2, ax=ax,color = \"black\")\n",
    "\n",
    "        hist_region = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        hist_region.fill(files[\"Mj_jesTotalDown_a\"][maskdict_sr(files,region)], weight = files[\"weight\"][maskdict_sr(files,region)])\n",
    "        hist_value_down = flow(hist_region)[0]\n",
    "        hist_var_down   = flow(hist_region)[1]\n",
    "        err_down = np.nan_to_num(error_bar(hist_value_nom, hist_var_nom, type = \"mc\"), nan = 0)\n",
    "        hep.histplot(hist_value_down, bins=hist_region.axes[0].edges, yerr=err_down, label=\"JES,total down\", histtype='step', stack=False, linewidth=2, ax=ax,color = \"blue\")\n",
    "        \n",
    "        err_up   = np.sqrt(np.power(err_up/hist_value_up,2) + np.power(err_nom/hist_value_nom,2))\n",
    "        hep.histplot(hist_value_up/hist_value_nom,   bins=hist_region.axes[0].edges, yerr=err_up, color='red',  label=\"JES,total up/center\", histtype='step', density=False, stack=False, ax=ax1,linewidth=2)\n",
    "        err_down = np.sqrt(np.power(err_down/hist_value_down,2) + np.power(err_nom/hist_value_nom,2))    \n",
    "        hep.histplot(hist_value_down/hist_value_nom, bins=hist_region.axes[0].edges, yerr=err_down, color='blue', label=\"JES,total down/center\",histtype='step', density=False, stack=False, ax=ax1,linewidth=2)    \n",
    "\n",
    "        ax1.set_xlabel(\"Higgs candidate MET recovery jet mass(GeV)\")\n",
    "        ax.set_ylabel(\"Events\")\n",
    "        ax1.set_ylabel(\"ratio\")\n",
    "        # ax.set_yscale('log') \n",
    "        ax.legend(loc=\"upper right\", ncol=1, frameon=False, fontsize=22)\n",
    "        ax1.legend(loc=\"upper right\", ncol=1, frameon=False, fontsize=20)\n",
    "        plt.text(0.05,0.83,region,fontsize=24, color=\"black\", ha='left',transform=ax.transAxes)\n",
    "        plt.savefig(f\"{plot_dir}/JES_{year}_{region}.pdf\", bbox_inches='tight')    \n",
    "    else: \n",
    "        hist_region = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        hist_region.fill(files[\"Mj_jerUp_a\"][maskdict_sr(files,region)], weight = files[\"weight\"][maskdict_sr(files,region)])\n",
    "        hist_value_up = flow(hist_region)[0]\n",
    "        hist_var_up   = flow(hist_region)[1]\n",
    "        err_up = np.nan_to_num(error_bar(hist_value_up, hist_var_up, type = \"mc\"), nan = 0)\n",
    "        hep.histplot(hist_value_up, bins=hist_region.axes[0].edges, yerr=err_up, label=\"JER,up\", histtype='step', stack=False, linewidth=2, ax=ax, color = \"red\")\n",
    "\n",
    "        hist_region = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        hist_region.fill(files[\"MH_Reco\"][maskdict_sr(files,region)], weight = files[\"weight\"][maskdict_sr(files,region)])\n",
    "        hist_value_nom = flow(hist_region)[0]\n",
    "        hist_var_nom   = flow(hist_region)[1]\n",
    "        err_nom = np.nan_to_num(error_bar(hist_value_nom, hist_var_nom, type = \"mc\"), nan = 0)\n",
    "        hep.histplot(hist_value_nom, bins=hist_region.axes[0].edges, yerr=err_nom, label=\"center\", histtype='step', stack=False, linewidth=2, ax=ax,color = \"black\")\n",
    "\n",
    "        hist_region = bh.Histogram(bh.axis.Regular(nbins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        hist_region.fill(files[\"Mj_jerDown_a\"][maskdict_sr(files,region)], weight = files[\"weight\"][maskdict_sr(files,region)])\n",
    "        hist_value_down = flow(hist_region)[0]\n",
    "        hist_var_down   = flow(hist_region)[1]\n",
    "        err_down = np.nan_to_num(error_bar(hist_value_nom, hist_var_nom, type = \"mc\"), nan = 0)\n",
    "        hep.histplot(hist_value_down, bins=hist_region.axes[0].edges, yerr=err_down, label=\"JER,down\", histtype='step', stack=False, linewidth=2, ax=ax,color = \"blue\")\n",
    "        \n",
    "        err_up   = np.sqrt(np.power(err_up/hist_value_up,2) + np.power(err_nom/hist_value_nom,2))\n",
    "        hep.histplot(hist_value_up/hist_value_nom,   bins=hist_region.axes[0].edges, yerr=err_up, color='red',  label=\"JER,up/center\", histtype='step', density=False, stack=False, ax=ax1,linewidth=2)\n",
    "        err_down = np.sqrt(np.power(err_down/hist_value_down,2) + np.power(err_nom/hist_value_nom,2))    \n",
    "        hep.histplot(hist_value_down/hist_value_nom, bins=hist_region.axes[0].edges, yerr=err_down, color='blue', label=\"JER,down/center\",histtype='step', density=False, stack=False, ax=ax1,linewidth=2)    \n",
    "\n",
    "        ax1.set_xlabel(\"Higgs candidate MET recovery jet mass(GeV)\")\n",
    "        ax.set_ylabel(\"Events\")\n",
    "        ax1.set_ylabel(\"ratio\")\n",
    "        # ax.set_yscale('log') \n",
    "        ax.legend(loc=\"upper right\", ncol=1, frameon=False, fontsize=22)\n",
    "        ax1.legend(loc=\"upper right\", ncol=1, frameon=False, fontsize=20)\n",
    "        plt.text(0.05,0.83,region,fontsize=24, color=\"black\", ha='left',transform=ax.transAxes)\n",
    "        plt.savefig(f\"{plot_dir}/JER_{year}_{region}.pdf\", bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_JES_JER_variation(files[\"TotalSignal\"],region = \"SR1a\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],region = \"SR1b\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],region = \"SR2a\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],region = \"SR2b\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],region = \"PS\")\n",
    "\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],plot_JES = False, region = \"SR1a\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],plot_JES = False, region = \"SR1b\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],plot_JES = False, region = \"SR2a\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],plot_JES = False, region = \"SR2b\")\n",
    "plot_JES_JER_variation(files[\"TotalSignal\"],plot_JES = False, region = \"PS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc8653c37afde981a02f518cc5ed66e36d68f5e1c41895fdf66da08341e86c45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
