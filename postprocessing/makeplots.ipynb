{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: This is the Jupyter notebook to do the flowing things:\n",
    "\n",
    "1. Read slimmed PKU Tree files to plot variables distribution\n",
    "\n",
    "Enviroment needed for this script: HWW\n",
    "\n",
    "(I have exported the enviroment needed for this script, assume you have `Conda` installed in your terminal, then enter `../envs/` directory, and use  `conda env create -f HWW.yml` to create the enviroment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import awkward as ak\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from scipy import interpolate\n",
    "from cycler import cycler\n",
    "import uproot\n",
    "import ROOT\n",
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import hist as hist2\n",
    "import pyarrow\n",
    "import yaml\n",
    "from typing import Dict, List, Union\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea.nanoevents.methods import vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = \"2018\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SlimmedTree files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the slimmedtree files using uproot\n",
    "\n",
    "#different year available here.\n",
    "year = YEAR\n",
    "# year = \"2016\"\n",
    "# year = \"2017\"\n",
    "# year = \"2018\"\n",
    "# year = \"Full-Run2\"\n",
    "\n",
    "#if run on PKU cluster, use this:\n",
    "# CustNanoData = {\n",
    "#     'data'        : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Data/SlimmedTree_Data.root\"%(year),\n",
    "#     'QCD'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/MC/SlimmedTree_QCD.root\"%(year),\n",
    "#     'Top'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/MC/SlimmedTree_Top.root\"%(year),\n",
    "#     'WJets'       : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/MC/SlimmedTree_WJets.root\"%(year),\n",
    "#     'Rest'        : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/MC/SlimmedTree_Rest.root\"%(year),\n",
    "#     'TotalSignal' : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_Total.root\"%(year),\n",
    "#     'ggF'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_GluGlu.root\"%(year),\n",
    "#     'VH'          : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_VH.root\"%(year),\n",
    "#     'ttH'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_ttH.root\"%(year),\n",
    "#     'VBF'         : \"/data/bond/zhaoyz/SlimmedTree/V6/%s/Signal/SlimmedTree_VBF.root\"%(year),\n",
    "# } \n",
    "\n",
    "#if run on lxplus, use this:\n",
    "# CustNanoData = {\n",
    "#     'data'        : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/Data/SlimmedTree_Data.root\"%(year),\n",
    "#     'QCD'         : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/MC/SlimmedTree_QCD.root\"%(year),\n",
    "#     'Top'         : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/MC/SlimmedTree_Top.root\"%(year),\n",
    "#     'WJets'       : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/MC/SlimmedTree_WJets.root\"%(year),\n",
    "#     'Rest'        : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/MC/SlimmedTree_Rest.root\"%(year),\n",
    "#     'TotalSignal' : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/Signal/SlimmedTree_Total.root\"%(year),\n",
    "#     'ggF'         : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/Signal/SlimmedTree_GluGlu.root\"%(year),\n",
    "#     'VH'          : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/Signal/SlimmedTree_VH.root\"%(year),\n",
    "#     'ttH'         : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/Signal/SlimmedTree_ttH.root\"%(year),\n",
    "#     'VBF'         : \"/eos/user/y/yuzhe/HWW/SlimmedTree/V5/%s/Signal/SlimmedTree_VBF.root\"%(year),\n",
    "# }  \n",
    "\n",
    "#if run on CMSconnect, use this:\n",
    "\n",
    "# CustNanoData = {\n",
    "#     'data'        : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/Data/SlimmedTree_Data.root\"%(year),\n",
    "#     'QCD'         : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/MC/SlimmedTree_QCD.root\"%(year),\n",
    "#     'Top'         : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/MC/SlimmedTree_Top.root\"%(year),\n",
    "#     'WJets'       : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/MC/SlimmedTree_WJets.root\"%(year),\n",
    "#     'Rest'        : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/MC/SlimmedTree_Rest.root\"%(year),\n",
    "#     'TotalSignal' : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/Signal/SlimmedTree_Total.root\"%(year),\n",
    "#     'ggF'         : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/Signal/SlimmedTree_GluGlu.root\"%(year),\n",
    "#     'VH'          : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/Signal/SlimmedTree_VH.root\"%(year),\n",
    "#     'ttH'         : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/Signal/SlimmedTree_ttH.root\"%(year),\n",
    "#     'VBF'         : \"/ospool/cms-user/yuzhe/SlimmedTree/V6/%s/Signal/SlimmedTree_VBF.root\"%(year),\n",
    "# }        \n",
    "\n",
    "\n",
    "BKG = [\"QCD\",\"Top\",\"WJets\",\"Rest\"]\n",
    "files = {typefile : {} for typefile in CustNanoData}\n",
    "for typefile in CustNanoData:\n",
    "    files[typefile] = uproot.lazy({CustNanoData[typefile]: \"PKUTree\" })\n",
    "    \n",
    "#for signal decomposition plots, we store these information in different objects\n",
    "files[r\"$H^{4q}$\"] = files[\"TotalSignal\"][files[\"TotalSignal\"][\"R4q_a\"] == 1]\n",
    "files[r\"$H^{3q}$\"] = files[\"TotalSignal\"][(files[\"TotalSignal\"][\"R3q_a\"] == 1) & (files[\"TotalSignal\"][\"R3q_taudecay_a\"] != 1)]\n",
    "files[\"W\"] = files[\"TotalSignal\"][files[\"TotalSignal\"][\"w_a\"] == 1]\n",
    "files[\"top\"] = files[\"TotalSignal\"][files[\"TotalSignal\"][\"t_a\"] == 1]\n",
    "files[\"Z\"] = files[\"TotalSignal\"][files[\"TotalSignal\"][\"z_a\"] == 1]\n",
    "files[r\"$H^{lqq}$\"] = files[\"TotalSignal\"][(files[\"TotalSignal\"][\"Rlqq_a\"] == 1) | (files[\"TotalSignal\"][\"R3q_taudecay_a\"] == 1)]\n",
    "files[\"g/q\"] = files[\"TotalSignal\"][files[\"TotalSignal\"][\"gKK_g_a\"] == 1]\n",
    "files[\"rest\"] = files[\"TotalSignal\"][(files[\"TotalSignal\"][\"u_a\"] == 1) | (files[\"TotalSignal\"][\"Rlq_a\"] == 1) | (files[\"TotalSignal\"][\"R2q_a\"] == 1)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DPhi in the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dphi(events):\n",
    "    pT_higgs   = events[\"PTj_V2_a\"]\n",
    "    eta_higgs  = events[\"Etaj_V2_a\"]\n",
    "    phi_higgs  = events[\"Phij_V2_a\"]\n",
    "    mass_higgs = events[\"Mj_V2_a\"]\n",
    "    pT_MET = events[\"MET_et\"]\n",
    "    eta_MET = events[\"Etaj_V2_a\"]\n",
    "    phi_MET = events[\"MET_phi\"]\n",
    "    mass_MET = ak.zeros_like(events[\"MET_phi\"])\n",
    "    vec_higgs = ak.zip({\n",
    "        \"pt\"   : pT_higgs   ,\n",
    "        \"eta\"  : eta_higgs  ,\n",
    "        \"phi\"  : phi_higgs  ,\n",
    "        \"mass\" : mass_higgs ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "    vec_MET = ak.zip({\n",
    "        \"pt\"   :   pT_MET   ,\n",
    "        \"eta\"  :  eta_MET  ,\n",
    "        \"phi\"  :  phi_MET  ,\n",
    "        \"mass\" : mass_MET ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "    delta_phi = np.subtract(vec_MET.phi, vec_higgs.phi)\n",
    "    delta_phi = np.where(delta_phi > np.pi, delta_phi - 2*np.pi, delta_phi)\n",
    "    delta_phi = np.where(delta_phi < -np.pi, delta_phi + 2*np.pi, delta_phi)\n",
    "    delta_phi = np.abs(delta_phi)\n",
    "    print(delta_phi)\n",
    "    events[\"DPhi\"] = delta_phi\n",
    "\n",
    "for k in files:\n",
    "    print(\"Add dphi of:\",k)\n",
    "    # get_dphi(events=files[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MET recovery mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_reco(events):\n",
    "    pT_higgs   = events[\"PTj_V2_a\"]\n",
    "    eta_higgs  = events[\"Etaj_V2_a\"]\n",
    "    phi_higgs  = events[\"Phij_V2_a\"]\n",
    "    mass_higgs = events[\"Mj_V2_a\"]\n",
    "    pT_MET = events[\"MET_et\"]\n",
    "    eta_MET = events[\"Etaj_V2_a\"]\n",
    "    phi_MET = events[\"MET_phi\"]\n",
    "    mass_MET = ak.zeros_like(events[\"MET_phi\"])\n",
    "    vec_higgs = ak.zip({\n",
    "        \"pt\"   : pT_higgs   ,\n",
    "        \"eta\"  : eta_higgs  ,\n",
    "        \"phi\"  : phi_higgs  ,\n",
    "        \"mass\" : mass_higgs ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "\n",
    "    vec_MET = ak.zip({\n",
    "        \"pt\"   :   pT_MET   ,\n",
    "        \"eta\"  :  eta_MET  ,\n",
    "        \"phi\"  :  phi_MET  ,\n",
    "        \"mass\" : mass_MET ,\n",
    "    },\n",
    "    with_name=\"PtEtaPhiMLorentzVector\",\n",
    "    behavior=vector.behavior,\n",
    "    )\n",
    "\n",
    "    vec_sum = vec_MET + vec_higgs\n",
    "    mH_reco = vec_sum.mass\n",
    "    events[\"MH_Reco\"] = ak.where(( (events[\"DPhi\"] < 0.8) & (events[\"MET_et\"]/events[\"PTj_V2_a\"] > 0.1)),mH_reco, events[\"Mj_V2_a\"])\n",
    "\n",
    "for k in files:\n",
    "    print(\"Add reco of:\",k)\n",
    "    # get_reco(events=files[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output all the variables for which we can make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"VBF\"].fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot setting, error setting, histogram setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import boost_histogram as bh\n",
    "from cycler import cycler\n",
    "\n",
    "use_helvet = False ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)\n",
    "\n",
    "def flow(hist: bh.Histogram, overflow: bool=True, underflow: bool=True):\n",
    "    h, var = hist.view(flow=(overflow | underflow)).value, hist.view(flow=(overflow | underflow)).variance\n",
    "    if overflow: \n",
    "        # h, var also include underflow bins but in plots usually no underflow data\n",
    "        # And we've filled None with -999, so we shouldn't show underflow data (mostly from filled None)\n",
    "        # You have to access the overflow and underflow bins data like below:\n",
    "        h[-2] += h[-1]; var[-2] += var[-1]\n",
    "    if underflow:\n",
    "        h[1] += h[0]; var[1] += var[0]\n",
    "    if overflow or underflow:\n",
    "        h, var = h[1:-1], var[1:-1]\n",
    "    return h, var\n",
    "    # Return the updated histogram and variance\n",
    "\n",
    "def error_bar(h, var, type='data'):\n",
    "    from scipy.interpolate import CubicSpline\n",
    "    if type == 'data':\n",
    "        number = h\n",
    "    elif type == 'mc':  # h = k*N, var = k^2*N, std = k*sqrt(N)\n",
    "        number = h**2 / var\n",
    "    else:\n",
    "        raise ValueError(\"type should be 'data' or 'mc'! \")\n",
    "    center = range(11) # Number: 0-10\n",
    "    up = np.array([1.84, 3.30, 4.64, 5.92, 7.16, 8.38, 9.58, 10.77, 11.95, 13.11, 14.27]) - center\n",
    "    down = center - np.array([0, 0.17, 0.71, 1.37, 2.09, 2.84, 3.62, 4.42, 5.23, 6.06, 6.89])\n",
    "    #cs means to create a CubicSpline object\n",
    "    cs_up = CubicSpline(x=center, y=up)\n",
    "    cs_down = CubicSpline(x=center, y=down)\n",
    "    \n",
    "    Garwood = (number>0)&(number<10)\n",
    "    poison_error_bar = np.sqrt(number)\n",
    "    up_error_bar = np.copy(poison_error_bar)\n",
    "    down_error_bar = np.copy(poison_error_bar)\n",
    "    up_error_bar[Garwood] = cs_up(number[Garwood])\n",
    "    down_error_bar[Garwood] = cs_down(number[Garwood])\n",
    "    if type == 'mc':\n",
    "        up_error_bar *= var/h\n",
    "        down_error_bar *= var/h\n",
    "    up_error_bar [up_error_bar < 0 ] = 0\n",
    "    down_error_bar [down_error_bar < 0 ] = 0\n",
    "    return np.array([down_error_bar, up_error_bar])\n",
    "\n",
    "\n",
    "# function to find the optimal region with S/sqrt(B)\n",
    "# not used so far\n",
    "def optimalcut(shist, bhist):\n",
    "    n_bins = len(shist)\n",
    "    best_lower = None\n",
    "    best_upper = None\n",
    "    best_s_sqrt_b = 0\n",
    "\n",
    "    for lower in range(n_bins):\n",
    "        for upper in range(lower+1, n_bins+1):\n",
    "            s = np.sum(shist[lower:upper])\n",
    "            b = np.sum(bhist[lower:upper])\n",
    "            s_sqrt_b = s / np.sqrt(b + 1)\n",
    "\n",
    "            if s_sqrt_b > best_s_sqrt_b:\n",
    "                best_lower = lower\n",
    "                best_upper = upper\n",
    "                best_s_sqrt_b = s_sqrt_b\n",
    "\n",
    "    return best_lower, best_upper, best_s_sqrt_b\n",
    "\n",
    "def optimalcut_oneside(shist, bhist, epsilon = 0.01):\n",
    "    '''\n",
    "    Given the signal histogram and background histogram, \n",
    "    show the one-side cut for the variable to get best s/sqrt(b).\n",
    "    Args:\n",
    "        shist:signal histogram\n",
    "        bhist:background histogram\n",
    "        epsilon(float): epsilon to avoid numerical errs \n",
    "    '''\n",
    "    n_bins = len(shist)\n",
    "    best_cut = 0\n",
    "    best_s_sqrt_b = 0\n",
    "\n",
    "    for cut in range(n_bins):\n",
    "        s = np.sum(shist[cut:])\n",
    "        b = np.sum(bhist[cut:])\n",
    "        s_sqrt_b = s / np.sqrt(b + epsilon)\n",
    "        if s_sqrt_b > best_s_sqrt_b:\n",
    "            best_cut = cut\n",
    "            best_s_sqrt_b = s_sqrt_b\n",
    "        \n",
    "    return best_cut, best_s_sqrt_b\n",
    "\n",
    "def optimalcut_mid_combine(shist1, shist2, bhist, epsilon = 1):\n",
    "    '''\n",
    "    Given the signal histogram and background histogram, \n",
    "    show the one-side cut for the variable to get best s/sqrt(b).\n",
    "    Args:\n",
    "        shist:signal histogram\n",
    "        bhist:background histogram\n",
    "        epsilon(float): epsilon to avoid numerical errs \n",
    "    '''\n",
    "    n_bins = len(shist1)\n",
    "    best_cut = 0\n",
    "    best_combined_sig_two_side = 0\n",
    "\n",
    "    for cut in range(n_bins):\n",
    "        s_right_side = np.sum(shist2[cut:])\n",
    "        b_right_side = np.sum(bhist[cut:])\n",
    "        s_left_side = np.sum(shist1[:cut])\n",
    "        b_left_side = np.sum(bhist[:cut])\n",
    "        s_sqrt_b_right_side = s_right_side / np.sqrt(b_right_side + epsilon)\n",
    "        s_sqrt_b_left_side = s_left_side / np.sqrt(b_left_side + epsilon)\n",
    "        combined_sig_two_side = np.sqrt((s_sqrt_b_right_side)**2 + (s_sqrt_b_left_side)**2)\n",
    "        if combined_sig_two_side > best_combined_sig_two_side:\n",
    "            best_cut = cut\n",
    "            best_combined_sig_two_side = combined_sig_two_side\n",
    "        \n",
    "    return best_cut, best_combined_sig_two_side\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define main plots function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "hep.style.use(\"CMS\")\n",
    "def makeplots(arrays, weight, plot_name: str, x_name: str, region = 'PS',othertext = \"\", year='2018', bins=40, x_min=0, x_max=2000, overflow=False, underflow=False, log = False, blind = False,  nametext = \"\" ,optimal_cut = True, deco = False):\n",
    "    '''\n",
    "    arrays: awkward array of the variable we want to plot\n",
    "    weight: awkward array of the weight of each event\n",
    "    plot_name: string of the plot name\n",
    "    x_name: x-axis name\n",
    "    region: the region we want to plot, according to the cut defined below\n",
    "    othertext: string to be added in the plots\n",
    "    year: year of the data used(2016, 2017, 2018, Full-Run2)\n",
    "    bins: number of bins\n",
    "    x_min(max): range of the variables to be plotted\n",
    "    overflow(underflow): bool variables, decide to use overflow/underflow or not, default set to False\n",
    "    log: bool variable, decide to use log scale or not, default set to False\n",
    "    blind: bool variable, decide to blind data or not, default set to False\n",
    "    nametext: string to be added in the file name\n",
    "    optimal_cut: bool variable, decide to plot optimal region or not, default set to True\n",
    "    deco: bool variable, decide to plot signal decomposition or not, if False, will plot different production mode of signal, default set to False\n",
    "    '''\n",
    "    # LUMI = {\"2016\": 36.33, \"2017\": 41.48, \"2018\": 59.83,\"Full-Run2\":138}\n",
    "    LUMI = {\"2016APV\": 19.52, \"2016\": 16.81, \"2017\": 41.48, \"2018\": 59.83,\"Full-Run2\":138}\n",
    "    bin_width = (x_max-x_min)/bins\n",
    "    \n",
    "    #blind data in this region\n",
    "    if blind:\n",
    "        mask = np.logical_or(arrays[\"data\"] <= 90, arrays[\"data\"] >= 150)\n",
    "        arrays[\"data\"] = arrays[\"data\"][mask]\n",
    "    \n",
    "    # canvas initializing\n",
    "    f = plt.figure(figsize=(9, 10))\n",
    "    gs = mpl.gridspec.GridSpec(3, 1, height_ratios=[6, 1, 1], hspace=0.08)\n",
    "    ax = f.add_subplot(gs[0])\n",
    "    plt.grid()\n",
    "    hep.cms.label(loc = 1, data=True, year=year, ax=ax, lumi=LUMI[year], fontsize=18, llabel='Preliminary')\n",
    "   \n",
    "    # ratio panel\n",
    "    ax1 = f.add_subplot(gs[1])\n",
    "    ax2 = f.add_subplot(gs[2])\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "        \n",
    "    # analyze\n",
    "    stacked = {'h': {}, 'var': {}} \n",
    "    individual = {'h': {}, 'var': {}}\n",
    "    BKG = [\"QCD\",\"Top\",\"WJets\",\"Rest\"]\n",
    "    for (k,v) in arrays.items():\n",
    "        hist = bh.Histogram(bh.axis.Regular(bins, x_min, x_max), storage=bh.storage.Weight())\n",
    "        values = ak.fill_none(v, -999)\n",
    "        if k!='data':\n",
    "            hist.fill(values, weight=weight[k])\n",
    "        else:\n",
    "            hist.fill(values)\n",
    "        h, var = flow(hist=hist, overflow=overflow, underflow=underflow)\n",
    "        if k in BKG: \n",
    "            stacked['h'][k] = h\n",
    "            stacked['var'][k] = var\n",
    "        else:\n",
    "            individual['h'][k] = h\n",
    "            individual['var'][k] = var        \n",
    "    \n",
    "    #plot\n",
    "    SIG_COLOR={'TotalSignal': 'black',\"ggF\":\"pink\",\"VH\":\"blue\",\"ttH\":\"yellow\",\"VBF\":\"aqua\"}\n",
    "    SIG_DECO_COLOR = {'TotalSignal': 'black',r\"$H^{4q}$\":\"green\",r\"$H^{3q}$\":\"orange\",\"W\":\"blue\",\"top\":\"purple\",\"Z\":\"yellow\",r\"$H^{lqq}$\":\"cyan\",\"g/q\":\"pink\",\"rest\":\"gray\"}\n",
    "    ax1.plot([x_min,x_max], [1,1], color='black', linestyle='dashed')\n",
    "    if len(stacked['h'].keys())>0:\n",
    "        BKG_list = [\"Rest\",\"WJets\",\"Top\",\"QCD\"]\n",
    "        err_list = [  np.nan_to_num(error_bar(stacked['h'][k], stacked['var'][k], type = \"mc\"), nan = 0) for k in BKG_list]\n",
    "        h_list = [stacked['h'][k] for k in BKG_list]\n",
    "        label_list = BKG_list\n",
    "        colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\",\"#d62728\"]\n",
    "        hep.histplot(h_list, bins=hist.axes[0].edges, label=label_list, yerr = err_list, histtype='fill', density=False, stack=True, linewidth=2, ax=ax,color = colors)\n",
    "        bkg_h = np.sum(list(stacked['h'].values()), axis=0)\n",
    "        bkg_err = np.sum(err_list ,  axis=0)\n",
    "        bin_edges = np.linspace(x_min, x_max, bins+1)\n",
    "        bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "        ax.errorbar(x = bin_centers,y = bkg_h, yerr=bkg_err, fmt='none', color='gray', capsize=2,markersize = 3)\n",
    "    \n",
    "    # Scale the signal according to total BKG to make it visiable:\n",
    "    NORM_s1=np.sum(bkg_h)/(np.sum(individual[\"h\"][\"TotalSignal\"])+0.000001)\n",
    "    print(\"Should scale signal * \",NORM_s1)\n",
    "    if                       NORM_s1>=300000: NORM_s1=300000\n",
    "    elif  300000>NORM_s1 and NORM_s1>=100000: NORM_s1= 100000\n",
    "    elif  100000>NORM_s1 and NORM_s1>= 30000: NORM_s1= 30000\n",
    "    elif   30000>NORM_s1 and NORM_s1>= 10000: NORM_s1=  10000\n",
    "    elif   10000>NORM_s1 and NORM_s1>=  3000: NORM_s1=  3000\n",
    "    elif    3000>NORM_s1 and NORM_s1>=  1000: NORM_s1=   1000\n",
    "    elif    1000>NORM_s1 and NORM_s1>=   300: NORM_s1=   300\n",
    "    elif     300>NORM_s1 and NORM_s1>=   100: NORM_s1=    100\n",
    "    elif     100>NORM_s1 and NORM_s1>=    30: NORM_s1=    30\n",
    "    elif      30>NORM_s1 and NORM_s1>=    10: NORM_s1=     10\n",
    "    else                                    : NORM_s1=     1   \n",
    "    \n",
    "    for (k,h) in individual['h'].items():\n",
    "        if k=='data': #data\n",
    "            err = error_bar(h, individual['var'][k], type='data')\n",
    "            hep.histplot(h, bins=hist.axes[0].edges, yerr=err, label=k, color='black', histtype='errorbar', density=False, stack=False, ax=ax)\n",
    "            ratio_error = np.sqrt(np.power(err/h,2) + np.power(bkg_err/bkg_h,2))\n",
    "            hep.histplot(h/bkg_h, bins=hist.axes[0].edges, yerr=ratio_error, color='black', histtype='errorbar', density=False, stack=False, ax=ax1)    \n",
    "            data_mc_ratio = np.sum(h)/np.sum(bkg_h)\n",
    "        else:  # signal\n",
    "            if deco != True: #plot signal in different production mode\n",
    "                if k in [\"TotalSignal\",\"ggF\",\"VH\",\"ttH\",\"VBF\"]:\n",
    "                    err = error_bar(h, individual['var'][k], type='mc')\n",
    "                    hep.histplot(h*NORM_s1, bins=hist.axes[0].edges, yerr=NORM_s1*err, label=k+r\"$\\times$\"+str(NORM_s1), histtype='step', density=False, stack=False, linewidth=2, ax=ax, color=SIG_COLOR[k])\n",
    "                    y = h / np.sqrt(bkg_h + 1)\n",
    "                    hep.histplot(y, bins=hist.axes[0].edges, yerr=err/np.sqrt(bkg_h+1), label=k, histtype='step', density=False, stack=False, ax=ax2, color=SIG_COLOR[k])\n",
    "            \n",
    "            else: #plot signal in signal decomposition mode\n",
    "                if k not in [\"ggF\",\"VH\",\"ttH\",\"VBF\"]:\n",
    "                    frac = \"(\" + \"%.1f\"%(np.sum(h)/np.sum(individual['h'][\"TotalSignal\"])*100)+ \"%)\"\n",
    "                    err = error_bar(h, individual['var'][k], type='mc')\n",
    "                    if k != \"TotalSignal\": hep.histplot(h*NORM_s1, bins=hist.axes[0].edges, yerr=NORM_s1*err, label=k+frac, histtype='step', density=False, stack=False, linewidth=2, ax=ax, color=SIG_DECO_COLOR[k])\n",
    "                    else:hep.histplot(h*NORM_s1, bins=hist.axes[0].edges, yerr=NORM_s1*err, label=k+r\"$\\times$\"+str(NORM_s1), histtype='step', density=False, stack=False, linewidth=2, ax=ax, color=SIG_DECO_COLOR[k])\n",
    "                    y = h / np.sqrt(bkg_h + 1)\n",
    "                    hep.histplot(y, bins=hist.axes[0].edges, yerr=err/np.sqrt(bkg_h+1), label=k, histtype='step', density=False, stack=False, ax=ax2, color=SIG_DECO_COLOR[k])\n",
    "            \n",
    "            if k == \"TotalSignal\": #print optimal cut information\n",
    "                best_lower, best_upper, best_s_sqrt_b = optimalcut(h,bkg_h)\n",
    "                print(\"Optimal two-side cut =\",best_lower, best_upper, best_s_sqrt_b)\n",
    "                best_cut, best_s_sqrt_b = optimalcut_oneside(h,bkg_h)\n",
    "                print(\"Optimal one-side cut =\",best_cut, best_s_sqrt_b) \n",
    "                best_cut, best_combined_sig_two_side = optimalcut_mid_combine(individual['h'][r\"$H^{4q}$\"],individual['h'][r\"$H^{lqq}$\"],bkg_h)\n",
    "                print(\"Optimal mid-side cut = \",best_cut,best_combined_sig_two_side)\n",
    "            \n",
    "            if optimal_cut == True: #add optimal cut information in the plot\n",
    "                cut_value_low = x_min + best_lower * (x_max - x_min)/bins\n",
    "                ax2.axvline(x=cut_value_low, color='r', linestyle='-')\n",
    "                ax2.annotate('', xy=(cut_value_low, ax2.get_ylim()[1]), xytext=(cut_value_low - (x_max - x_min)/20 , ax2.get_ylim()[1]),arrowprops=dict(facecolor='red', arrowstyle=\"->\"))                \n",
    "                cut_value_up = x_min + best_upper * (x_max - x_min)/bins\n",
    "                ax2.axvline(x=cut_value_up, color='r', linestyle='-')\n",
    "                ax2.annotate('', xy=(cut_value_up, ax2.get_ylim()[1]), xytext=(cut_value_up + (x_max - x_min)/20 , ax2.get_ylim()[1]),arrowprops=dict(facecolor='red', arrowstyle=\"->\"))                \n",
    "                if cut_value_low < (x_max - cut_value_up):\n",
    "                    text_position = cut_value_up + (x_max - x_min)/20\n",
    "                    ax2.text(text_position, ax2.get_ylim()[1], r'$S/\\sqrt{B+1}$'+\"=%s\"%(str(round(best_s_sqrt_b,3))), verticalalignment='center', horizontalalignment='left',fontsize = 13)\n",
    "                else: \n",
    "                    text_position = cut_value_low - (x_max - x_min)/20\n",
    "                    ax2.text(text_position, ax2.get_ylim()[1], r'$S/\\sqrt{B+1}$'+\"=%s\"%(str(round(best_s_sqrt_b,3))), verticalalignment='center', horizontalalignment='right',fontsize = 13)\n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    \n",
    "    # plot setting\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(ax.get_ylim()[0], ax.get_ylim()[1]*1e1)\n",
    "    else:\n",
    "        ax.set_ylim(0.01, ax.get_ylim()[1]*1.3)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=0)\n",
    "\n",
    "    \n",
    "    # set the range of data/MC ratio plot\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_ylim(0, 2)\n",
    "    ax1.set_ylabel(r'$\\frac{Data}{bkg\\ MC}$', ha='center', fontsize=24)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    # set the range of s/sqrt(b) plot\n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    ax2.set_ylim(0, ax2.get_ylim()[1]*1.4)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax2.set_xlabel(x_name, fontsize=22, ha='right', x=1)\n",
    "    ax2.set_ylabel(r'$S/\\sqrt{B+1}$', ha='center', fontsize=16)\n",
    "    ax2.ticklabel_format(useOffset=False, style='plain')\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=16)\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    \n",
    "    if blind:\n",
    "        plt.text(0.05,0.83,region + \" \" + othertext + \" blinded\",fontsize=17, color=\"black\", ha='left',transform=ax.transAxes)\n",
    "    else:\n",
    "        plt.text(0.05,0.83,region + othertext + \" Data/MC = \" + str(round(data_mc_ratio,3)),fontsize=17, color=\"black\", ha='left',transform=ax.transAxes)        \n",
    "    ax.legend(loc=\"upper right\", ncol=2, frameon=False, fontsize=13)\n",
    "    \n",
    "    # suffix in filename\n",
    "    suffix = ''\n",
    "    if deco: suffix += \"_DECO\"\n",
    "    \n",
    "    #change this string to set the path\n",
    "    path_str = './plots/makeplots/22Mar2024'\n",
    "    if not os.path.exists(path_str):\n",
    "        os.makedirs(path_str)\n",
    "    plt.savefig(f\"{path_str}/{year}_{plot_name}{suffix}_{region}_{othertext}_{nametext}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the cut for each regions, for examples, SRs, CRs, PS and MET regions here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUT = {        \n",
    "    \"SR1a\" : {k:  (files[k][\"MH_Reco\"] >= 50) & (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] <= 0.25) & (files[k][\"a_HWW_V2\"] >= 0.99) for k in files}, \n",
    "    \"SR1b\" : {k:  (files[k][\"MH_Reco\"] >= 50) & (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] <= 0.25) & (files[k][\"a_HWW_V2\"] >= 0.92) & (files[k][\"a_HWW_V2\"] < 0.99) for k in files},   \n",
    "    \"SR2a\" : {k:  (files[k][\"MH_Reco\"] >= 50) & (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] > 0.25) & (files[k][\"a_HWW_V2\"] >= 0.99) & (files[k][\"DPhi\"] < 0.8)for k in files}, \n",
    "    \"SR2b\" : {k:  (files[k][\"MH_Reco\"] >= 50) & (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] > 0.25) & (files[k][\"a_HWW_V2\"] >= 0.92) & (files[k][\"a_HWW_V2\"] < 0.99) & (files[k][\"DPhi\"] < 0.8)for k in files},   \n",
    "    # \"CR1\"  : {k:  (files[k][\"MH_Reco\"] >= 50) & (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] <= 0.25) & (files[k][\"a_HWW_V2\"] < 0.92) for k in files},\n",
    "    # \"CR2\"  : {k:  (files[k][\"MH_Reco\"] >= 50) & (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] > 0.25)  & (files[k][\"a_HWW_V2\"] < 0.92) & (files[k][\"DPhi\"] < 0.8) for k in files},   \n",
    "    # \"PS\"   : {k:  (files[k][\"MH_Reco\"] >= 0)  for k in files}, \n",
    "    # \"LowMET\"   : {k:  (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] <= 0.25)  for k in files},\n",
    "    # \"HighMET\"  : {k:  (files[k][\"MET_et\"]/files[k][\"PTj_V2_a\"] > 0.25)   for k in files},   \n",
    "    }\n",
    "\n",
    "# CR: tagger < 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the variables we want to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_makeplots(region = \"PS\", events = files, nametext = \"\", blind = False, othertext = \"\", deco = False, optimal_cut = True, year = YEAR):\n",
    "    weight={k: events[k][CUT[region][k]][\"weight\"] for k in events}  # weight for each event\n",
    "    makeplots(arrays = {k: events[k][CUT[region][k]][\"MH_Reco\"] for k in events},    region = region, nametext = nametext, othertext = othertext,plot_name='MH_Reco', x_name=r'$jet_{a}$:MET recovery Mass', x_max=250, x_min=50,  bins=20, weight =weight, year=year,blind = blind, deco = deco,optimal_cut = optimal_cut)\n",
    "    makeplots(arrays = {k: events[k][CUT[region][k]][\"PTj_V2_a\"] for k in events},   region = region, nametext = nametext, othertext = othertext,plot_name='pT', x_name=r'$jet_{a}:p_{T}$', x_max=1000, x_min=200, bins=20, weight =weight, year=year,blind = blind, deco = deco,optimal_cut = optimal_cut)\n",
    "    makeplots(arrays = {k: events[k][CUT[region][k]][\"DPhi\"] for k in events},       region = region, nametext = nametext, othertext = othertext,plot_name='dphi', x_name=r'$\\Delta \\Phi $(Higgs candidate, MET)', x_max=3.2, x_min=0, bins=20, weight =weight, year=year,blind = blind, deco = deco,optimal_cut = optimal_cut)\n",
    "    makeplots(arrays = {k: events[k][CUT[region][k]][\"Etaj_V2_a\"] for k in events},  region = region, nametext = nametext, othertext = othertext,plot_name='eta', x_name=r'$\\eta$: Higgs candidate', x_max=3.2, x_min=-3.2, bins=20, weight =weight, year=year,blind = blind, deco = deco,optimal_cut = optimal_cut)\n",
    "    # add the variables you want to plot here, like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_makeplots(region = \"PS\", blind = False,  othertext = \"\", deco = True)\n",
    "# run_makeplots(region = \"SR1a\", blind = True,  othertext = \"\", deco = True) #this set to deco to True\n",
    "# run_makeplots(region = \"CR1\",  blind = False,  othertext = \"\", deco = True)\n",
    "# run_makeplots(region = \"SR2a\", blind = True,  othertext = \"\", deco = True) #this set to deco to True\n",
    "# run_makeplots(region = \"SR1b\", blind = True,  othertext = \"\", deco = True) #this set to deco to True\n",
    "# run_makeplots(region = \"SR2b\", blind = True,  othertext = \"\", deco = True) #this set to deco to True\n",
    "# run_makeplots(region = \"CR2\",  blind = False,  othertext = \"\", deco = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACE_HOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make plots for each region, some examples are shown here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_makeplots(region = \"SR1a\", blind = True,  othertext = \"example text\") #this will lead to the string \"example text\" added in the plot\n",
    "run_makeplots(region = \"CR1\",  blind = False, othertext = \"\") #this will show full data/MC results\n",
    "run_makeplots(region = \"SR2a\", blind = True,  othertext = \"\", deco = True) #this set to deco to True\n",
    "run_makeplots(region = \"SR2b\", blind = True,  othertext = \"\", optimal_cut = False) #this won't show optimal cut plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc8653c37afde981a02f518cc5ed66e36d68f5e1c41895fdf66da08341e86c45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
